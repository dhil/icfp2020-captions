1
00:00:56,480 --> 00:01:01,480


2
00:02:07,440 --> 00:02:12,440


3
00:03:17,520 --> 00:03:22,520


4
00:04:21,000 --> 00:04:26,000


5
00:05:15,000 --> 00:05:20,000


6
00:06:18,720 --> 00:06:23,720


7
00:08:15,840 --> 00:08:20,840


8
00:09:30,000 --> 00:09:33,000


9
00:11:40,520 --> 00:11:43,240
JEREMY GIBBONS: Hello, my
name is Jeremy Gibbons,

10
00:11:43,240 --> 00:11:44,800
together with Shriram Krishnamurthi,

11
00:11:44,800 --> 00:11:48,320
I'm editor in chief of
The Journal of Functional Programming.

12
00:11:48,320 --> 00:11:52,720
This year, we are trying out a new
interaction between JFP and ICFP.

13
00:11:52,720 --> 00:11:55,040
Authors of JFP papers
published in the previous year

14
00:11:55,040 --> 00:11:57,160
are offered the opportunity
to present their work

15
00:11:57,160 --> 00:11:58,960
at that year's conference

16
00:11:58,960 --> 00:12:00,440
provided that the paper
hasn't arisen out

17
00:12:00,440 --> 00:12:02,840
of an earlier presentation.

18
00:12:02,840 --> 00:12:05,480
This year authors of eight
papers took up the opportunity

19
00:12:05,480 --> 00:12:08,000
and their presentations are
collected in this session.

20
00:12:08,000 --> 00:12:11,600
Copies of those papers are freely
accessible on the JFP website

21
00:12:11,600 --> 00:12:14,680
with links from the ICFP website.

22
00:12:14,680 --> 00:12:16,400
The session is being streamed twice

23
00:12:16,400 --> 00:12:18,440
one is at a convenient
time in New York

24
00:12:18,440 --> 00:12:22,120
and again 11 hours later,
at a convenient time in Asia.

25
00:12:22,120 --> 00:12:24,640
I remind you that registered
ICFP participants

26
00:12:24,640 --> 00:12:26,400
will get the full
experience through Clowdr

27
00:12:26,400 --> 00:12:30,040
including text chat during the talk.

28
00:12:30,040 --> 00:12:31,720
Depending on the availability
of the authors,

29
00:12:31,720 --> 00:12:35,080
there may also be a live video
Q&A session after the talk

30
00:12:35,080 --> 00:12:38,760
in the New York stream and I will
announce that at the end of the talk

31
00:12:38,760 --> 00:12:43,120
but there's no live Q&A
in the Asia stream.

32
00:12:43,120 --> 00:12:45,200
The first talk is
a presentation of the paper,

33
00:12:45,200 --> 00:12:48,320
A Theory of RPC Calculi
for Client-Server Model

34
00:12:48,320 --> 00:12:50,720
which extends existing
stateless calculi

35
00:12:50,720 --> 00:12:53,040
to cover stateful interactions.

36
00:12:53,040 --> 00:12:55,560
The authors of the paper are
Kwanghoon Choi

37
00:12:55,560 --> 00:12:59,080
and Byeong-Mo Chang
and Kwanghoon will be presenting.

38
00:13:01,000 --> 00:13:02,720
KWANGHOON CHOI: Hello everyone.

39
00:13:02,720 --> 00:13:04,400
I'd like to give a talk about

40
00:13:04,400 --> 00:13:06,960
A Theory of RPC
Calculi for Client-Server Model.

41
00:13:08,000 --> 00:13:09,960
My name is Kwanghoon Choi,

42
00:13:09,960 --> 00:13:13,520
this is a joint work
with Byeong-Mo Chan.

43
00:13:13,520 --> 00:13:15,800
Let me start with the background.

44
00:13:15,800 --> 00:13:20,800
Developing distributed systems is
known as complex and error-prone.

45
00:13:21,360 --> 00:13:23,960
For example, consider a web system.

46
00:13:23,960 --> 00:13:27,680
You have to develop two
programs, one for client

47
00:13:27,680 --> 00:13:29,360
and the other for server in

48
00:13:29,360 --> 00:13:33,160
generally, in two
different programming languages.

49
00:13:33,160 --> 00:13:37,200
Also, the two programs
need to be put together

50
00:13:37,200 --> 00:13:41,040
for testing and maintenance.

51
00:13:41,040 --> 00:13:42,800
Tierless programming languages

52
00:13:42,800 --> 00:13:45,760
also known also called
multitier programming languages

53
00:13:45,760 --> 00:13:48,400
can address this problem.

54
00:13:48,400 --> 00:13:52,840
You have only to develop
a single tierless program.

55
00:13:52,840 --> 00:13:55,080
Assuming a client-server model,

56
00:13:55,080 --> 00:14:01,480
a slicing compiler will automatically
slice it into a client program

57
00:14:01,480 --> 00:14:03,600
and a server program.

58
00:14:03,600 --> 00:14:07,520
The communication between
the two sliced programs

59
00:14:07,520 --> 00:14:11,520
will be automatically supported.

60
00:14:11,520 --> 00:14:15,560
Particularly, we are
interested in a seamlessly

61
00:14:15,560 --> 00:14:19,640
tierless programming language
for client-server model.

62
00:14:19,640 --> 00:14:24,160
It is basically a programming language
designed for a single computer

63
00:14:24,160 --> 00:14:29,560
but naturally extended
with a seamless RPC.

64
00:14:29,560 --> 00:14:33,040
By the seamless remote
procedure call, RPC,

65
00:14:33,040 --> 00:14:37,720
I mean the remote procedure
calls are language supported,

66
00:14:37,720 --> 00:14:43,040
bi-directional
and fully transparent.

67
00:14:43,040 --> 00:14:47,800
Links is a real-world seamlessly
tierless programming language

68
00:14:47,800 --> 00:14:50,840
for a client-server model.

69
00:14:50,840 --> 00:14:55,840
One advantage of a seamlessly
tierless programming language is this.

70
00:14:56,360 --> 00:15:00,600
If you look at this example
program written in links,

71
00:15:00,600 --> 00:15:07,600
you know that tierless program can
be written exactly in the same way

72
00:15:07,600 --> 00:15:10,440
as writing single computer programs.

73
00:15:10,440 --> 00:15:14,880
The only difference is specifying
the location function.

74
00:15:14,880 --> 00:15:19,480
Here, client means that
the main is a client function

75
00:15:19,480 --> 00:15:22,520
that must run at client.

76
00:15:22,520 --> 00:15:27,280
Here, server means that
the authenticate is a server function

77
00:15:27,280 --> 00:15:31,560
that must run as server.

78
00:15:31,560 --> 00:15:36,560
Firstly, it is language
supported not library-based.

79
00:15:37,360 --> 00:15:42,280
Second, you can call a server
function from the client

80
00:15:42,280 --> 00:15:46,760
and also you can call a client
function from the server,

81
00:15:46,760 --> 00:15:49,480
so, it is bi-directional.

82
00:15:49,480 --> 00:15:54,880
Third, the same syntax of
lambda application is used,

83
00:15:54,880 --> 00:15:58,960
both for local procedure call
and remote procedure call.

84
00:15:58,960 --> 00:16:03,880
No extra RPC keyword is
used in the syntax.

85
00:16:03,880 --> 00:16:08,040
So, links is a seamlessly
tierless programming language

86
00:16:08,040 --> 00:16:11,680
for client-server model.

87
00:16:11,680 --> 00:16:16,120
The RPC calculus is
a seamlessly tierless calculus

88
00:16:16,120 --> 00:16:21,120
that extends the lambda
calculus with an RPC feature.

89
00:16:22,000 --> 00:16:29,320
It was proposed as a foundation
of links by Cooper and Wadler.

90
00:16:29,320 --> 00:16:33,760
In the calculus, c is
the client location,

91
00:16:33,760 --> 00:16:37,480
s denote the server location.

92
00:16:37,480 --> 00:16:41,160
Every lambda extraction has
a location annotation a

93
00:16:41,160 --> 00:16:46,160
meaning that this must run
at a specified location a.

94
00:16:47,720 --> 00:16:51,400
The RPC feature is described

95
00:16:51,400 --> 00:16:52,920
by the big steps semantics.

96
00:16:54,160 --> 00:16:58,000
When you evaluate a lambda
application at location a,

97
00:16:59,000 --> 00:17:01,240
you evaluate the functional term L

98
00:17:01,960 --> 00:17:03,280
at the same location a

99
00:17:04,520 --> 00:17:08,240
into a lambda abstraction with
location annotation b.

100
00:17:09,480 --> 00:17:12,680
You also evaluate an argument M

101
00:17:14,160 --> 00:17:16,440
to our value W at the same location.

102
00:17:17,920 --> 00:17:24,240
And then finally you do beta
reduction at the location b not a.

103
00:17:24,840 --> 00:17:27,440
In the semantic rule for
lambda application,

104
00:17:28,440 --> 00:17:32,920
the caller location a,
and the function location is b.

105
00:17:33,920 --> 00:17:40,400
If a is different from b, then
the lambda application LM

106
00:17:40,400 --> 00:17:42,160
is a remote procedure call.

107
00:17:42,640 --> 00:17:47,080
If a is the same as b,
it is a local procedure call.

108
00:17:47,600 --> 00:17:53,480
We use the same syntax for both
calls so it is fully transparent.

109
00:17:55,480 --> 00:17:59,160
The seamless RPC is good for
tireless programming.

110
00:17:59,640 --> 00:18:03,600
However, due to the transparency
of the seamless RPC

111
00:18:04,840 --> 00:18:08,400
every lambda abstraction has to
check the function location

112
00:18:08,400 --> 00:18:12,400
in runtime to decide
if it is RPC or not.

113
00:18:13,160 --> 00:18:17,520
This happens even in the sliced
client and server programs

114
00:18:17,520 --> 00:18:19,360
after the slicing compilation.

115
00:18:21,600 --> 00:18:25,000
Our solution is to have
located function types

116
00:18:25,720 --> 00:18:28,640
to track function
location statically.

117
00:18:29,400 --> 00:18:35,480
Then we can statically decide
if given lambda application

118
00:18:35,960 --> 00:18:38,880
is local procedure call
or remote procedure call.

119
00:18:39,880 --> 00:18:45,960
As a result, programmers can enjoy
the advantage of the seamless RPC

120
00:18:46,720 --> 00:18:48,000
in the tierless programs

121
00:18:48,760 --> 00:18:52,280
but no more runtime location
checking is required

122
00:18:52,760 --> 00:18:55,880
in the sliced client
and server programs.

123
00:18:58,880 --> 00:19:02,400
A key idea behind our
typed RPC calculus

124
00:19:03,920 --> 00:19:07,240
is a location annotation
on a function type.

125
00:19:08,520 --> 00:19:12,720
It is a reminiscent of a location
annotation on a lambda abstraction.

126
00:19:14,000 --> 00:19:16,280
The located function type means that

127
00:19:16,800 --> 00:19:18,960
every lambda abstraction
of this type

128
00:19:19,480 --> 00:19:24,560
must run, is guaranteed to run
at a specified location a.

129
00:19:25,560 --> 00:19:28,040
For example the argument f

130
00:19:28,760 --> 00:19:30,160
has a client function type

131
00:19:30,920 --> 00:19:35,160
because a client function is
going to be bounded to f.

132
00:19:36,160 --> 00:19:40,920
In the second example, f has
neither a client function type

133
00:19:40,920 --> 00:19:42,360
nor a server function type.

134
00:19:43,600 --> 00:19:47,080
Because depending on
the value of if conditional

135
00:19:48,080 --> 00:19:51,760
was client function and server function
can be bounded to f.

136
00:19:53,000 --> 00:19:54,800
In the typed RPC calculus

137
00:19:55,320 --> 00:19:57,880
only monomorphic
locations are allowed

138
00:19:57,880 --> 00:19:59,520
so it is not well typed.

139
00:20:01,760 --> 00:20:06,760
The other key idea is that
in the typed RPC calculus

140
00:20:06,760 --> 00:20:12,880
you can identify all remote procedure
calls statically in compared time.

141
00:20:14,160 --> 00:20:16,160
Let us see, it is typing rule.

142
00:20:17,440 --> 00:20:22,440
This is a refinement of the conventional
lambda application typing rule

143
00:20:22,440 --> 00:20:25,440
with respect to a caller location A

144
00:20:25,960 --> 00:20:28,160
and a function location B.

145
00:20:29,160 --> 00:20:33,200
Once your tierless program
is successfully type checked

146
00:20:33,920 --> 00:20:35,840
in every lambda application LM

147
00:20:36,600 --> 00:20:39,760
the caller location A
and the function location B

148
00:20:40,240 --> 00:20:44,600
are fully analyzed
and known in compile time.

149
00:20:45,840 --> 00:20:51,440
Then caller location a is equal
to the function location b

150
00:20:51,440 --> 00:20:55,640
then that lambda application
is local procedure call.

151
00:20:56,920 --> 00:21:00,040
Otherwise a is different from b

152
00:21:00,760 --> 00:21:03,200
then this is a remote
procedure call.

153
00:21:04,480 --> 00:21:08,920
In this way, you can statically decide
if given lambda application

154
00:21:09,440 --> 00:21:11,600
is local or remote procedure calls.

155
00:21:12,600 --> 00:21:14,920
By the type soundness property

156
00:21:14,920 --> 00:21:18,920
every remote procedure call
does analyze statically

157
00:21:19,680 --> 00:21:22,840
will never be dynamically
changed into any local one.

158
00:21:25,600 --> 00:21:27,120
Thanks to this property,

159
00:21:27,120 --> 00:21:32,120
we can design a location information
directed slicing compilation

160
00:21:33,560 --> 00:21:36,360
whose sliced clients and server programs

161
00:21:36,360 --> 00:21:41,360
will never do location checking,
dynamically in a long time.

162
00:21:42,560 --> 00:21:46,120
This is an advantage over
the untyped RPC calculus

163
00:21:46,120 --> 00:21:48,400
that always does location checking

164
00:21:48,920 --> 00:21:51,880
in the sliced client
and server programs.

165
00:21:55,400 --> 00:21:58,360
The typed RPC calculus
is good so far

166
00:21:58,840 --> 00:22:00,800
but it has a problem

167
00:22:01,320 --> 00:22:04,520
because of using only
monomorphic locations

168
00:22:04,520 --> 00:22:06,280
such as client and server

169
00:22:06,800 --> 00:22:09,240
not something to record both.

170
00:22:10,240 --> 00:22:12,840
For example you cannot write

171
00:22:12,840 --> 00:22:16,240
a single polymorphically
located map function.

172
00:22:16,960 --> 00:22:19,520
Instead you have to write
a client map function

173
00:22:19,520 --> 00:22:22,000
and a server map
function separately.

174
00:22:24,280 --> 00:22:27,520
A solution is to introduce
polymorphic locations

175
00:22:28,240 --> 00:22:29,720
to the typed RPC calculus.

176
00:22:31,440 --> 00:22:35,280
It is proposed by our sequel
research to the JFP paper

177
00:22:36,040 --> 00:22:38,600
about a polymorphic RPC calculus.

178
00:22:38,600 --> 00:22:43,280
This is joint work with James Cheney,
Simon Fowler and Sam Lindley.

179
00:22:44,800 --> 00:22:46,840
In the polymorphic RPC calculus,

180
00:22:46,840 --> 00:22:49,440
you can write a polymorphically
located function

181
00:22:49,440 --> 00:22:52,440
with the location abstraction
over location variable

182
00:22:53,160 --> 00:22:56,160
and location application
as you see in the slide.

183
00:22:56,160 --> 00:22:59,200
Then you have only to apply
to the client location

184
00:22:59,200 --> 00:23:00,800
to get a client map function.

185
00:23:02,040 --> 00:23:05,120
You can also apply to
the server location

186
00:23:06,120 --> 00:23:07,560
to get a server map function.

187
00:23:09,040 --> 00:23:12,160
This slide shows the comparison
among the RPC calculi

188
00:23:12,680 --> 00:23:16,440
to support the slicing compilation
of the polymorphic RPC calculus

189
00:23:16,920 --> 00:23:18,280
there are two approaches.

190
00:23:18,280 --> 00:23:21,840
One is a study approach that is
described in the sequel paper

191
00:23:22,360 --> 00:23:25,640
the other is a dynamic approach
that we are currently working on.

192
00:23:26,640 --> 00:23:31,240
In this talk, I presented
theory of RPC calculi.

193
00:23:31,240 --> 00:23:34,000
There are potential
application of location types

194
00:23:34,000 --> 00:23:37,480
to other areas such as securities
and communication optimization.

195
00:23:38,200 --> 00:23:41,120
Also, we want to develop
a fully fledged seamless

196
00:23:41,120 --> 00:23:43,560
tierless functional from
the language based on the series.

197
00:23:44,040 --> 00:23:45,720
Thank you for your attention.

198
00:23:45,720 --> 00:23:50,720
(APPLAUSE)

199
00:23:53,320 --> 00:23:54,760
JEREMY: Thanks Kwanghoon.

200
00:23:56,040 --> 00:23:57,760
If you are watching
the New York stream in Clowdr

201
00:23:57,760 --> 00:23:59,200
you should now see a Q&A link,

202
00:23:59,200 --> 00:24:02,000
where I hope you can ask
Kwanghoon question by video chat.

203
00:24:08,520 --> 00:24:10,760
The next talk is
the presentation of the paper

204
00:24:10,760 --> 00:24:13,040
The Full Reducing Krivine
Abstract Machine KN

205
00:24:13,040 --> 00:24:15,720
simulates pure normal-order reduction
in lockstep

206
00:24:16,200 --> 00:24:18,640
which adds to the framework
for environment machines

207
00:24:18,640 --> 00:24:21,680
developed by Małgorzata Biernacka
and Olivier Danvy.

208
00:24:22,680 --> 00:24:26,520
The authors of the paper are
Alvaro Garcia-Perez and Pablo Nogueira

209
00:24:27,000 --> 00:24:28,360
And Alvaro will be presenting it.

210
00:24:28,880 --> 00:24:30,240
ALVARO GARCIA-PEREZ: In this talk,

211
00:24:30,240 --> 00:24:32,240
we prove properties of
an abstract machine.

212
00:24:32,760 --> 00:24:35,920
In particular that the machine
defines the same strategy

213
00:24:35,920 --> 00:24:38,280
than the normal other strategy
of the lambda calculus.

214
00:24:39,280 --> 00:24:42,240
We prove this result by
introducing a semantic artifact

215
00:24:42,240 --> 00:24:44,080
that corresponds to the machine

216
00:24:44,080 --> 00:24:46,440
and it is retrofitted for
the proof of the property.

217
00:24:47,440 --> 00:24:50,520
The corresponding artifact is
a reduction strategy in a calculus

218
00:24:50,520 --> 00:24:51,520
of closures.

219
00:24:52,520 --> 00:24:54,560
As this quote by Cregut shows,

220
00:24:54,560 --> 00:24:58,080
the importance of full reduction
is widely recognized

221
00:24:58,080 --> 00:25:01,280
in the full implementation of programming
languages and (INAUDIBLE).

222
00:25:02,040 --> 00:25:06,160
Full reduction refers to reducing
the term up to a normal form.

223
00:25:06,160 --> 00:25:08,800
That is a term without redexes

224
00:25:09,800 --> 00:25:12,760
For instance, this is especially
important with nowadays

225
00:25:12,760 --> 00:25:14,520
proof assistants with
dependent types

226
00:25:14,520 --> 00:25:17,560
which needs to reach
the normal form of a type

227
00:25:17,560 --> 00:25:20,040
in order to implement
type conversion rules.

228
00:25:20,800 --> 00:25:24,400
The machine we study is Cregut's
full reducing version of

229
00:25:24,400 --> 00:25:25,680
the Krivine abstract machine

230
00:25:26,200 --> 00:25:27,520
which we abbreviate to KN.

231
00:25:28,520 --> 00:25:31,520
In a nutshell, KN takes
as input a lambda term

232
00:25:31,520 --> 00:25:34,880
that it embeds in closure in
an environment that preserves bindings

233
00:25:35,400 --> 00:25:37,240
and uses a continuation stack

234
00:25:37,240 --> 00:25:41,080
and tracks the lambda nesting
level of the term being evaluated.

235
00:25:42,320 --> 00:25:44,120
The machine looks up in environment

236
00:25:44,120 --> 00:25:47,000
the binding of a variable
represented by a De Bruijn index

237
00:25:47,520 --> 00:25:50,160
pushes the operand of
an application onto the stack

238
00:25:51,160 --> 00:25:54,160
retrieves such an operand when
the operator is an abstraction

239
00:25:54,160 --> 00:25:56,240
and place it as a binding
in the environment.

240
00:25:57,480 --> 00:25:59,640
Reduces the body of
an applied abstraction

241
00:25:59,640 --> 00:26:01,600
by pushing a special
symbol on the stack

242
00:26:02,080 --> 00:26:04,960
and placing in the environment
the lambda nesting level

243
00:26:04,960 --> 00:26:06,480
of the formal parameter
of the abstraction.

244
00:26:07,480 --> 00:26:11,080
Calculates the De Bruijn index
of such a formal parameter

245
00:26:11,080 --> 00:26:12,440
retrieved from the environment,

246
00:26:13,200 --> 00:26:15,520
reduces the operand
of a normal form

247
00:26:15,520 --> 00:26:17,560
which is embedded in
a special kind of closure

248
00:26:17,560 --> 00:26:19,080
that preserves (INAUDIBLE) terms.

249
00:26:19,560 --> 00:26:23,000
And finally flattens
the stack into a normal form

250
00:26:23,000 --> 00:26:26,600
that is returned when all
the symbols in the stack are consumed.

251
00:26:27,840 --> 00:26:30,960
KN has been proven to find
the normal form of a term

252
00:26:30,960 --> 00:26:32,000
when it has some.

253
00:26:32,520 --> 00:26:35,400
However the machine is
a first order transition system

254
00:26:35,400 --> 00:26:38,360
that manipulates environments
and continuation stacks at the low level.

255
00:26:39,360 --> 00:26:41,600
And this format is not ready
to the deploy proofs by

256
00:26:41,600 --> 00:26:42,680
structural induction.

257
00:26:44,400 --> 00:26:47,880
Our approach is to introduce a
higher order calculus of closures

258
00:26:47,880 --> 00:26:50,440
with a reduction strategy
that mimics the machine

259
00:26:50,960 --> 00:26:53,800
and that is suited for
proofs by structural induction.

260
00:26:54,560 --> 00:26:58,680
And later to prove that the said
calculus realizes the normal order

261
00:26:58,680 --> 00:27:00,640
strategy of
the pure lambda calculus.

262
00:27:01,880 --> 00:27:04,240
We arrived at such
calculus of closures

263
00:27:04,240 --> 00:27:07,680
from the ones in the tradition of
Curien's calculus of closures

264
00:27:07,680 --> 00:27:08,680
lambda rho.

265
00:27:09,640 --> 00:27:12,160
Curien's calculus
contains proper closures

266
00:27:12,160 --> 00:27:14,520
made up of a term
and an environment.

267
00:27:15,760 --> 00:27:18,080
The term uses the De Bruijn
indices representation,

268
00:27:19,080 --> 00:27:20,720
the environment stores closures

269
00:27:20,720 --> 00:27:24,040
and the indices are used to access
the bindings in the environment

270
00:27:24,520 --> 00:27:27,240
where positions in
the environment start at 0.

271
00:27:28,000 --> 00:27:31,480
In the example here,
reduction starts with a closure

272
00:27:31,480 --> 00:27:32,800
with empty environment.

273
00:27:33,800 --> 00:27:35,640
When an application is reached

274
00:27:36,120 --> 00:27:38,240
it's operand is embedded
into a closure

275
00:27:38,240 --> 00:27:40,360
and prepended to
the current environment.

276
00:27:41,360 --> 00:27:45,520
Then the binding at position
0 is looked up and retrieved

277
00:27:45,520 --> 00:27:46,800
from the environment.

278
00:27:47,560 --> 00:27:50,240
And then reduction
resumes on such bindings.

279
00:27:51,000 --> 00:27:53,160
In the beta rule of this calculus

280
00:27:53,160 --> 00:27:54,720
the operator in an application

281
00:27:54,720 --> 00:27:58,280
is reduced in multiple step fashion
to a weak head normal form.

282
00:27:59,520 --> 00:28:02,760
This poses some problems when
defining a reduction relation

283
00:28:02,760 --> 00:28:04,200
which is purely single step.

284
00:28:05,440 --> 00:28:07,680
This issue whilst
observed and fixed

285
00:28:07,680 --> 00:28:11,080
in the Biernacka and Danvy's
Lambda hat Rho calculus.

286
00:28:12,320 --> 00:28:16,120
This variant of Curien's
calculus considers a constructor

287
00:28:16,120 --> 00:28:17,680
for closure application

288
00:28:17,680 --> 00:28:20,800
that enables the reduction
relations to be lifted

289
00:28:20,800 --> 00:28:22,320
to the scope of the operator.

290
00:28:23,840 --> 00:28:26,480
The calculus also includes
an expansion rule

291
00:28:26,480 --> 00:28:29,240
that expands applications
to closure applications.

292
00:28:30,480 --> 00:28:33,800
This mechanism is reminiscent
of the apply stage

293
00:28:33,800 --> 00:28:36,960
in the eval-apply evaluators
in the classical literature

294
00:28:36,960 --> 00:28:38,640
in higher order
functional programming.

295
00:28:40,160 --> 00:28:42,400
Now reduction expands applications.

296
00:28:43,120 --> 00:28:44,920
Reduces the operator if needed,

297
00:28:44,920 --> 00:28:46,760
performs beta reduction

298
00:28:47,240 --> 00:28:50,280
and then continues to
reduce as before.

299
00:28:51,040 --> 00:28:54,000
The Biernacka and Danvy's
lambda hat rho

300
00:28:54,000 --> 00:28:55,640
is enough for weak reduction.

301
00:28:56,360 --> 00:28:59,440
They give account of
both call by name and call by value

302
00:28:59,440 --> 00:29:01,400
weak reducing strategies
in this calculus.

303
00:29:02,160 --> 00:29:05,400
However it cannot accommodate
full reducing strategies.

304
00:29:06,640 --> 00:29:09,920
We remedy this by further
extending the calculus

305
00:29:09,920 --> 00:29:12,760
with a construction for
closure abstraction.

306
00:29:13,760 --> 00:29:16,080
We also provide a new expansion rule

307
00:29:16,840 --> 00:29:19,320
that expands abstractions
into closure abstractions.

308
00:29:20,600 --> 00:29:22,560
But before presenting
this rule in detail

309
00:29:23,040 --> 00:29:25,960
we discuss how to represent
the formal parameter

310
00:29:25,960 --> 00:29:27,520
of the abstraction
in the environment.

311
00:29:28,800 --> 00:29:32,600
In calculus, a variable is
represented by a De Bruijn index

312
00:29:33,320 --> 00:29:35,280
which stands for
the relative distance

313
00:29:35,280 --> 00:29:37,760
between the applied
occurrence of the variable

314
00:29:37,760 --> 00:29:41,200
and it's binding occurrence
in the abstract syntax tree.

315
00:29:42,720 --> 00:29:46,080
If the binding lambda is
immediately above the variable,

316
00:29:46,840 --> 00:29:47,960
then the index is 0.

317
00:29:48,480 --> 00:29:52,080
Otherwise the index gets
incremented as the distance

318
00:29:52,080 --> 00:29:53,680
to its binding lambda increases.

319
00:29:55,920 --> 00:29:59,760
However if we place the De Bruijn
index of the formal parameter

320
00:29:59,760 --> 00:30:03,080
in a scope which is nested
under more lambdas

321
00:30:03,080 --> 00:30:04,440
than it's binding occurrence,

322
00:30:04,920 --> 00:30:07,480
then we have to adjust that
index by adding to it

323
00:30:07,480 --> 00:30:09,480
the number of lambdas going down.

324
00:30:11,240 --> 00:30:15,080
Inspired by KN, we used
instead De Bruijn level

325
00:30:15,080 --> 00:30:17,640
of the formal parameter
here over lined

326
00:30:18,160 --> 00:30:20,800
which stands for the absolute
lambda nesting level

327
00:30:20,800 --> 00:30:23,080
of the binding lambda in
the abstract index tree.

328
00:30:24,320 --> 00:30:26,400
One stands for the first lambda.

329
00:30:26,880 --> 00:30:30,320
And the level increases if
the binding lambda is further down.

330
00:30:31,560 --> 00:30:33,600
The advantage of
the De Bruijn levels

331
00:30:33,600 --> 00:30:37,240
is that they need not be a adjusted
when placed in scopes of the term

332
00:30:37,240 --> 00:30:39,200
that are nested under more lambdas.

333
00:30:40,200 --> 00:30:41,920
In order to use the De Bruijn level

334
00:30:42,440 --> 00:30:44,920
we first decorate our
reduction relation

335
00:30:44,920 --> 00:30:46,760
with the current
lambda nesting level.

336
00:30:47,520 --> 00:30:50,680
And then the expansion rule
pushes into the environment

337
00:30:50,680 --> 00:30:52,720
the current level increment by one.

338
00:30:52,720 --> 00:30:55,000
Since the formal parameter
has crossed the lambda.

339
00:30:56,000 --> 00:30:59,400
We also add to the calculus
a construction for such levels

340
00:30:59,920 --> 00:31:03,880
and we restrict the environments
to either contain proper closures

341
00:31:03,880 --> 00:31:07,880
or levels since this would be
enough for the reduction strategy

342
00:31:07,880 --> 00:31:09,240
that mimics KN.

343
00:31:10,240 --> 00:31:12,320
When the level is retrieved
from the environment

344
00:31:12,320 --> 00:31:15,560
the index corresponding
to it can be calculated

345
00:31:15,560 --> 00:31:18,640
by subtracting the level from
the current lambda nesting level.

346
00:31:19,640 --> 00:31:21,960
A new rule takes care
of this calculation

347
00:31:22,480 --> 00:31:25,920
and embeds the calculated
index into a new construction

348
00:31:25,920 --> 00:31:27,080
for absolute indices.

349
00:31:28,360 --> 00:31:31,680
Absolute indices are formal parameters
of an applied abstractions

350
00:31:31,680 --> 00:31:33,960
that are not relative
to any environment.

351
00:31:34,960 --> 00:31:38,080
We show an example of a reduction
sequence in our calculus.

352
00:31:38,840 --> 00:31:41,880
The sequence starts with
a term within the environment

353
00:31:41,880 --> 00:31:44,320
and expands the application
into a closure application.

354
00:31:45,320 --> 00:31:48,800
But now it also expands
the operator to a closure abstraction

355
00:31:48,800 --> 00:31:50,480
before performing the beta step

356
00:31:50,960 --> 00:31:53,640
which replaces the formal
parameter by the operand

357
00:31:54,120 --> 00:31:56,640
then the sequence goes on as before.

358
00:31:57,880 --> 00:31:59,840
We also show how reduction acts

359
00:31:59,840 --> 00:32:01,680
on any applied abstraction.

360
00:32:02,160 --> 00:32:04,560
The abstraction is expanded
to a closure abstraction

361
00:32:04,560 --> 00:32:07,320
and later the level of
the formal parameter

362
00:32:07,320 --> 00:32:09,040
is retrieved from the environment.

363
00:32:10,040 --> 00:32:13,360
Now reduction moves the scope to
the body of the closure abstraction

364
00:32:13,360 --> 00:32:15,960
by the means of a compatibility rule

365
00:32:16,480 --> 00:32:19,320
that increments the level decoration
of the reduction relation.

366
00:32:20,320 --> 00:32:22,680
Combined with the rule
for index calculation

367
00:32:23,400 --> 00:32:26,600
this results in the level
one of the formal parameter

368
00:32:26,600 --> 00:32:29,680
being subtracted from
the current lambda nesting level.

369
00:32:30,200 --> 00:32:33,240
Which is embedded as
the absolute index 0.

370
00:32:35,000 --> 00:32:37,400
Notice that the input term
was already a normal form

371
00:32:37,920 --> 00:32:41,440
and that reduction has only
performed administrative steps

372
00:32:41,440 --> 00:32:44,520
which amount to flattening
the explicit substitution in the closure

373
00:32:44,520 --> 00:32:45,680
into a term.

374
00:32:47,200 --> 00:32:50,200
Our main result is a one
to one correspondence

375
00:32:50,200 --> 00:32:53,920
between the non-administrative
steps in our calculus

376
00:32:53,920 --> 00:32:56,480
and the steps of normal
order in lambda.

377
00:32:58,240 --> 00:33:01,400
This correspondence is captured
by the commuting diagram here.

378
00:33:02,160 --> 00:33:05,360
On the top, 0 or more
administrative steps

379
00:33:05,360 --> 00:33:07,080
followed by one beta step

380
00:33:07,600 --> 00:33:10,200
correspond to the one
beta step on the bottom.

381
00:33:11,480 --> 00:33:15,480
A substitution function sigma
mediates between the closures above

382
00:33:15,480 --> 00:33:16,840
and the terms below.

383
00:33:17,840 --> 00:33:20,680
The substitution function
flattens the closure

384
00:33:20,680 --> 00:33:23,200
by performing only
administrative reduction.

385
00:33:24,720 --> 00:33:27,160
The main technique used in
the proof of this result

386
00:33:27,160 --> 00:33:29,840
is a structural induction
on the derivation trees

387
00:33:29,840 --> 00:33:31,200
of reduction judgments

388
00:33:31,200 --> 00:33:32,640
which has been possible

389
00:33:32,640 --> 00:33:35,480
thanks to the features of
our calculus of closures.

390
00:33:36,480 --> 00:33:40,400
In a previous work, we used
program transformation techniques

391
00:33:40,400 --> 00:33:42,840
to interderive KN

392
00:33:42,840 --> 00:33:45,920
..and the reduction in
strategy in our calculus.

393
00:33:45,920 --> 00:33:49,000
Together with this previous
work, our main result entails

394
00:33:49,000 --> 00:33:51,040
that KN and normal order,

395
00:33:51,040 --> 00:33:55,600
perform the same beta reduction
steps, and in the same order.

396
00:33:55,600 --> 00:33:58,840
To conclude, our contribution
has been possible

397
00:33:58,840 --> 00:34:01,080
thanks to the
integration techniques,

398
00:34:01,080 --> 00:34:03,280
and to our judicious use
of scopes and levels

399
00:34:03,280 --> 00:34:06,000
in our calculus of closures.

400
00:34:06,000 --> 00:34:09,280
We have proven our result, which is
stronger than the known result,

401
00:34:09,280 --> 00:34:14,400
that KN finds the normal form
of a term, if it exists.

402
00:34:14,400 --> 00:34:15,800
Our contribution adds

403
00:34:15,800 --> 00:34:19,640
to the increasing corpus of
knowledge of full reduction.

404
00:34:19,640 --> 00:34:21,840
We conjecture that
variants of our calculus

405
00:34:21,840 --> 00:34:23,720
could be used to
prove similar results

406
00:34:23,720 --> 00:34:26,120
for other full reducing strategies.

407
00:34:26,120 --> 00:34:31,120
In particular for the eager strategies
in the call by value family.

408
00:34:47,800 --> 00:34:55,720
(APPLAUSE)

409
00:34:55,720 --> 00:34:57,120
JEREMY GIBBONS: Thanks, Alvaro.

410
00:34:57,120 --> 00:34:59,640
If you're watching the New
York stream in Clowdr,

411
00:34:59,640 --> 00:35:01,040
you should now see a Q&A link,

412
00:35:01,040 --> 00:35:05,200
where you can ask Alvaro
questions by video chat.

413
00:35:10,240 --> 00:35:12,120
The next talk is
a presentation of the paper

414
00:35:12,120 --> 00:35:14,080
Local Algebraic Effects Theories,

415
00:35:14,080 --> 00:35:17,000
which extends the algebraic
effects and handlers approach

416
00:35:17,000 --> 00:35:20,320
to track which equational theory
the effects are required to satisfy

417
00:35:20,320 --> 00:35:23,080
in which sub-parts of a program.

418
00:35:23,080 --> 00:35:26,240
The authors of the paper are
Ziga Luksic and Matija Pretnar,

419
00:35:26,240 --> 00:35:29,720
and Ziga will be presenting.

420
00:35:29,720 --> 00:35:31,160
ZIGA LUKSIC: Hi, I'm Ziga Luksic,

421
00:35:31,160 --> 00:35:33,920
and I will present joint
work with Matija Pretnar,

422
00:35:33,920 --> 00:35:37,840
on local algebraic effect
theories, which was developed

423
00:35:37,840 --> 00:35:42,840
to aid with reasoning in
languages with effect handlers.

424
00:35:42,840 --> 00:35:46,600
In reasoning about programs, we
often rely on certain equivalences

425
00:35:46,600 --> 00:35:50,000
such as the ones stemming from
mathematical properties.

426
00:35:50,000 --> 00:35:54,040
For instance, the functions f1
and f2 can be considered equal,

427
00:35:54,040 --> 00:35:57,880
since x+x = 2*x.

428
00:35:57,880 --> 00:36:00,280
Program equivalence gets much harder

429
00:36:00,280 --> 00:36:03,040
when we start using
computational effects.

430
00:36:03,040 --> 00:36:04,720
For instance, when using print,

431
00:36:04,720 --> 00:36:08,480
it's not entirely clear whether
printing the same string twice,

432
00:36:08,480 --> 00:36:11,920
is the same as printing
a double string.

433
00:36:11,920 --> 00:36:15,000
We do not know whether the language
adds a new line separator

434
00:36:15,000 --> 00:36:16,360
at the end of each output,

435
00:36:16,360 --> 00:36:20,480
or perhaps the prints are
counted for a message log.

436
00:36:20,480 --> 00:36:22,240
We must therefore know the specifics

437
00:36:22,240 --> 00:36:24,240
of the language implementation.

438
00:36:24,240 --> 00:36:26,680
So just imagine how much
more difficult it becomes

439
00:36:26,680 --> 00:36:30,120
if effect behavior is user defined.

440
00:36:30,120 --> 00:36:31,800
This is precisely the case

441
00:36:31,800 --> 00:36:35,080
in languages with
algebraic effect handlers.

442
00:36:35,080 --> 00:36:38,640
In such a language, effects
are modeled by operations

443
00:36:38,640 --> 00:36:43,000
which are assigned types in
the so called effect signature.

444
00:36:43,000 --> 00:36:45,640
For instance, here we have
an operation Choose,

445
00:36:45,640 --> 00:36:48,000
that represents a binary choice.

446
00:36:48,000 --> 00:36:52,720
It accepts a unit argument
and returns a boolean value.

447
00:36:52,720 --> 00:36:54,880
The operation itself is only a construct,

448
00:36:54,880 --> 00:36:57,000
and its behavior is specified

449
00:36:57,000 --> 00:37:00,520
by the handler that intercepts
the operation call.

450
00:37:00,520 --> 00:37:05,760
The choose_true handler has
an effect case for Choose,

451
00:37:05,760 --> 00:37:09,280
and here we have the unit
argument of the operation call,

452
00:37:09,280 --> 00:37:11,760
and the program continuation k,

453
00:37:11,760 --> 00:37:17,200
which is captured at
the time of the operation call.

454
00:37:17,200 --> 00:37:21,120
The effect case states that
whenever Choose is invoked,

455
00:37:21,120 --> 00:37:25,000
the continuation is resumed
with the value true.

456
00:37:25,000 --> 00:37:30,400
This causes every call of Choose
to simply return the value of true.

457
00:37:31,400 --> 00:37:35,280
Now when using this handler,
the behaviour is crystal clear.

458
00:37:35,280 --> 00:37:40,840
The code always returns one,
because Choose always returns true.

459
00:37:40,840 --> 00:37:43,240
And for a slightly more
interesting example,

460
00:37:43,240 --> 00:37:48,680
if we build a function choice, that
returns one of its two arguments,

461
00:37:48,680 --> 00:37:52,480
where the selection is,
again done with Choose,

462
00:37:52,480 --> 00:37:56,320
we can again use the handler
that always returns true.

463
00:37:56,320 --> 00:38:01,400
And in that case, choice always
chooses the last argument.

464
00:38:01,400 --> 00:38:04,640
So the functions f1
and f2 are equal,

465
00:38:04,640 --> 00:38:09,640
since... well, they both
always return zero.

466
00:38:09,640 --> 00:38:12,480
They're also equivalent
in a broader sense.

467
00:38:12,480 --> 00:38:16,520
Every handler that results in
an associative implementation of choice

468
00:38:16,520 --> 00:38:19,800
results in f1 being
equivalent to f2.

469
00:38:19,800 --> 00:38:22,320
So another instance of
a suitable handler

470
00:38:22,320 --> 00:38:26,120
is one that collects
all possible results.

471
00:38:26,120 --> 00:38:28,000
And on the other hand,

472
00:38:28,000 --> 00:38:32,520
if we randomly select one of
the options with a 50% chance,

473
00:38:32,520 --> 00:38:35,880
that is not a suitable
implementation.

474
00:38:35,880 --> 00:38:41,880
The main issue here is how
exactly to state such a property.

475
00:38:41,880 --> 00:38:46,520
One way to do that is to use
equations. In the original approach,

476
00:38:46,520 --> 00:38:50,440
to effect handlers, the theory
consisted of an effect signature

477
00:38:50,440 --> 00:38:53,360
and equations between operations.

478
00:38:53,360 --> 00:38:55,840
For instance,
associativity of choice,

479
00:38:55,840 --> 00:38:58,280
which is what we wanted
in the previous example,

480
00:38:58,280 --> 00:39:02,800
can easily be expressed
with an equation.

481
00:39:02,800 --> 00:39:05,680
Using equations allows
us to abstract away

482
00:39:05,680 --> 00:39:08,400
from concrete implementations.

483
00:39:08,400 --> 00:39:13,320
We can focus on effect
implementations that satisfy

484
00:39:13,320 --> 00:39:18,120
certain requirements that are
set by the equational theory.

485
00:39:18,120 --> 00:39:22,920
The original approach assumes
a single global effect theory,

486
00:39:22,920 --> 00:39:25,880
but this turned out to
be very restricting.

487
00:39:25,880 --> 00:39:27,400
There are many useful handlers

488
00:39:27,400 --> 00:39:30,480
that work with entirely
different theories, and

489
00:39:30,480 --> 00:39:35,880
by fixing the global theory,
we are unable to use some of them.

490
00:39:35,880 --> 00:39:38,520
This is where our work comes in.

491
00:39:38,520 --> 00:39:41,280
We transition to local theories

492
00:39:41,280 --> 00:39:46,280
by packing equations into
computation types instead.

493
00:39:47,080 --> 00:39:51,960
A computation type now states
the type of return values,

494
00:39:51,960 --> 00:39:55,120
the names and types of
operations that may be called,

495
00:39:55,120 --> 00:39:58,040
and the equational theory.

496
00:39:58,040 --> 00:40:01,840
At this type, all computations
are considered equivalent,

497
00:40:01,840 --> 00:40:05,120
modulo the equations ε.

498
00:40:05,120 --> 00:40:08,080
Let's take a look at
a small example.

499
00:40:08,080 --> 00:40:11,160
In this signature, we
define an operation signal

500
00:40:11,160 --> 00:40:14,200
that accepts a unit
and returns a unit.

501
00:40:14,200 --> 00:40:16,480
It truly does nothing
more than just signal

502
00:40:16,480 --> 00:40:19,360
to the handler that it was called.

503
00:40:19,360 --> 00:40:23,200
And in the effect theory we
can be a bit more expressive.

504
00:40:23,200 --> 00:40:26,080
The equation states that
if we signal twice,

505
00:40:26,080 --> 00:40:29,080
and then proceed with
an arbitrary computation, that

506
00:40:29,080 --> 00:40:32,200
is no different than
if we signal only once

507
00:40:32,200 --> 00:40:34,520
and then continue with z.

508
00:40:34,520 --> 00:40:37,200
Now an example of a handler
that fits the equation

509
00:40:37,200 --> 00:40:40,760
is one that returns true as
soon as a signal occurs,

510
00:40:40,760 --> 00:40:46,000
and false if the computation is
evaluated without a single signal.

511
00:40:47,000 --> 00:40:51,840
And an example of handler that
does not respect the equation

512
00:40:51,840 --> 00:40:53,800
would be a handler that instead

513
00:40:53,800 --> 00:40:58,000
returns the number of
signals received.

514
00:40:59,240 --> 00:41:00,960
We can now use this equation

515
00:41:00,960 --> 00:41:04,800
to restrict possible
effect implementations.

516
00:41:04,800 --> 00:41:07,520
Here we have two
functions f1 and f2,

517
00:41:07,520 --> 00:41:12,520
and f1 has no equations, while
f2 uses the above equation.

518
00:41:12,520 --> 00:41:16,720
This means that f1 can be handled
by any handler for signal,

519
00:41:16,720 --> 00:41:19,880
while f2 requires
the handler to now differentiate

520
00:41:19,880 --> 00:41:22,400
between one and many signals.

521
00:41:22,400 --> 00:41:27,920
We can of course use such handlers
for f1 as well, but not vice versa.

522
00:41:28,720 --> 00:41:31,760
This already shows the difference
between global and local theories,

523
00:41:31,760 --> 00:41:34,120
since in the global
setting, we either require

524
00:41:34,120 --> 00:41:38,120
all handlers to respect
the equation, or none of them.

525
00:41:38,120 --> 00:41:41,600
In the first case, we can't use
such a wide variety of handlers

526
00:41:41,600 --> 00:41:44,160
for handling f1,
and in the second case,

527
00:41:44,160 --> 00:41:51,640
we can't use the equation as
a reasoning tool in the body of the f2.

528
00:41:51,640 --> 00:41:55,320
And when implementing effective
behaviour with handlers,

529
00:41:55,320 --> 00:41:57,000
we of course need to be mindful of

530
00:41:57,000 --> 00:41:59,400
the effect theory that
we're working in.

531
00:41:59,400 --> 00:42:02,800
Handler type informs us about
the kind of computations

532
00:42:02,800 --> 00:42:05,040
that the handler is used for,

533
00:42:05,040 --> 00:42:08,080
and what the resulting
computation type is.

534
00:42:08,080 --> 00:42:11,880
Since two computation
types are involved,

535
00:42:11,880 --> 00:42:14,640
equations occur in two spots.

536
00:42:14,640 --> 00:42:18,360
The ε on the left sets
the requirements for the implementation,

537
00:42:18,360 --> 00:42:22,960
and ε′ on the right states
the theory of the outgoing type.

538
00:42:23,680 --> 00:42:27,120
We have to check that
for every equation in ε,

539
00:42:27,120 --> 00:42:32,240
if we handle both sides, we end
up with equivalent computations.

540
00:42:32,240 --> 00:42:36,280
The equivalence is considered
in the theory of ε′,

541
00:42:36,280 --> 00:42:42,560
so we may be aided by
the equations that are packed in ε′.

542
00:42:42,560 --> 00:42:45,160
Handler correctness is undecidable.

543
00:42:45,160 --> 00:42:48,400
So the proofs are
constructed in a logic

544
00:42:48,400 --> 00:42:52,200
that is coupled with
the type system.

545
00:42:53,760 --> 00:42:58,080
Using equations comes with extra
work when typing handlers,

546
00:42:58,080 --> 00:43:00,160
but provides a strong
tool for reasoning

547
00:43:00,160 --> 00:43:04,880
and it's a very natural
fit for algebraic effects.

548
00:43:04,880 --> 00:43:08,520
Local effect theories impose less
restrictions than global ones

549
00:43:08,520 --> 00:43:14,000
and we consider them an all around
improvement over global theories.

550
00:43:14,000 --> 00:43:17,600
Equations are vital for
reasoning about effect behaviour.

551
00:43:17,600 --> 00:43:21,320
And the type system can also be
coupled with different kinds of logic.

552
00:43:21,320 --> 00:43:26,320
So we can use a system that
fits the problem at hand.

553
00:43:27,880 --> 00:43:30,640
Or If we use local effect theories,

554
00:43:30,640 --> 00:43:33,360
the changes to the language
are rather minor,

555
00:43:33,360 --> 00:43:36,920
and the resulting system
is also easy to use.

556
00:43:36,920 --> 00:43:40,080
We do not need to switch to
denotational semantics,

557
00:43:40,080 --> 00:43:45,080
or to a full-fledged
dependently typed setting.

558
00:43:45,760 --> 00:43:50,160
The drawback is clearly the need for
user input when typing handlers,

559
00:43:50,160 --> 00:43:53,760
but handler definitions are
the only point where this is required,

560
00:43:53,760 --> 00:43:58,320
so most of the work
is still automated.

561
00:43:58,320 --> 00:43:59,640
Since the paper was published,

562
00:43:59,640 --> 00:44:03,160
we have done some
considerable advancements.

563
00:44:03,160 --> 00:44:05,920
We have extended
the language with recursion

564
00:44:05,920 --> 00:44:09,720
and some basic data types,
such as products or lists.

565
00:44:09,720 --> 00:44:14,160
We also included the non-trivial
extension of subtyping,

566
00:44:14,160 --> 00:44:18,040
which greatly improves
the usefulness of the language.

567
00:44:18,040 --> 00:44:22,480
All of this has been formalized
in the Coq proof assistant,

568
00:44:22,480 --> 00:44:25,120
alongside some smaller examples.

569
00:44:25,120 --> 00:44:26,760
And we also constructed a

570
00:44:26,760 --> 00:44:29,240
sound and adequate
denotational semantics,

571
00:44:29,240 --> 00:44:33,920
which takes into account all
the aforementioned extensions.

572
00:44:33,920 --> 00:44:38,640
The approach was also implemented
on top of the Eff framework.

573
00:44:38,640 --> 00:44:42,120
We decided to use
a bi-directional type inference

574
00:44:42,120 --> 00:44:46,280
as it's more suited for
working with effect theories.

575
00:44:46,280 --> 00:44:49,760
But the system does not
automate correctness proofs,

576
00:44:49,760 --> 00:44:51,600
which are left to the user.

577
00:44:51,600 --> 00:44:54,320
The proofs can be done
by pen and paper,

578
00:44:54,320 --> 00:44:56,120
or they can also be constructed

579
00:44:56,120 --> 00:44:59,600
in the Coq formalization
of the language.

580
00:45:00,440 --> 00:45:03,120
We also considered
a few future goals.

581
00:45:03,120 --> 00:45:08,800
The important extension that has
not yet been done is polymorphism.

582
00:45:08,800 --> 00:45:12,320
We wish to have types that are
polymorphic in the value component,

583
00:45:12,320 --> 00:45:16,840
as well as polymorphic in
the signature and equations.

584
00:45:16,840 --> 00:45:18,520
The extension could
be far from trivial

585
00:45:18,520 --> 00:45:21,960
but it's ultimately important
if you want a language,

586
00:45:21,960 --> 00:45:24,360
that can be used in practice.

587
00:45:24,360 --> 00:45:27,600
Another key aspect that we're
not yet entirely satisfied with,

588
00:45:27,600 --> 00:45:30,640
is proving handler correctness.

589
00:45:30,640 --> 00:45:34,440
Automation would be great,
but even just easing the burden

590
00:45:34,440 --> 00:45:42,920
by providing better tools for user
proofs would be a great start.

591
00:45:43,600 --> 00:45:46,040
Perhaps also very important is

592
00:45:46,040 --> 00:45:51,480
finding good use cases for
local effect theories.

593
00:45:51,480 --> 00:45:53,800
We feel that we are now at the point

594
00:45:53,800 --> 00:45:57,400
where future work should
be guided by shortcomings

595
00:45:57,400 --> 00:46:03,080
when trying to apply it
to actual problems.

596
00:46:03,080 --> 00:46:06,360
Anyone interested is
welcome to read our paper,

597
00:46:06,360 --> 00:46:08,840
and thank you for your time.

598
00:46:08,840 --> 00:46:17,480
(APPLAUSE)

599
00:46:17,480 --> 00:46:19,080
JEREMY: Thanks, Ziga.

600
00:46:19,080 --> 00:46:21,400
If you're watching the New
York stream in Clowdr,

601
00:46:21,400 --> 00:46:22,760
you should now see a Q&A link,

602
00:46:22,760 --> 00:46:26,440
where you can get
questions by video chat.

603
00:46:31,560 --> 00:46:34,200
The next talk is a presentation
of the functional pearl,

604
00:46:34,200 --> 00:46:37,040
heterogeneous binary
random-access lists.

605
00:46:37,040 --> 00:46:39,400
Which you can use for example,
to implement efficient

606
00:46:39,400 --> 00:46:42,520
typed environments for
a well typed interpreter.

607
00:46:42,520 --> 00:46:45,600
The paper's by Wouter Swierstra.

608
00:46:45,600 --> 00:46:47,880
WOUTER SWIERSTRA: Thank you
for that introduction, Jeremy.

609
00:46:47,880 --> 00:46:50,560
So my name is Wouter Swierstra,
and I'm here to say a little bit about

610
00:46:50,560 --> 00:46:53,640
the functional pearl that
I published in JFP last year.

611
00:46:53,640 --> 00:46:56,160
So let's start by
talking about lists.

612
00:46:56,160 --> 00:46:57,920
So lists are one of
the very first data types

613
00:46:57,920 --> 00:47:00,040
that we teach our
undergrad students.

614
00:47:00,040 --> 00:47:02,440
And they're a great vehicle
for explaining concepts

615
00:47:02,440 --> 00:47:05,200
such as higher order function
with maps and folds,

616
00:47:05,200 --> 00:47:07,520
recursion, or polymorphism.

617
00:47:07,520 --> 00:47:08,920
But as our students mature,

618
00:47:08,920 --> 00:47:10,880
they typically take one
of two career paths

619
00:47:10,880 --> 00:47:13,280
if they're interested in
functional programming.

620
00:47:13,280 --> 00:47:15,960
On the one hand, if they
choose to go into industry,

621
00:47:15,960 --> 00:47:17,800
they quickly realize that
if they need to store

622
00:47:17,800 --> 00:47:21,400
any serious amount of data, you
need better data structures,

623
00:47:21,400 --> 00:47:25,160
such as finite maps or some
form of balanced binary tree.

624
00:47:25,160 --> 00:47:28,040
Other students might pursue
a career in academia.

625
00:47:28,040 --> 00:47:30,320
And in that case, they
spend their time writing

626
00:47:30,320 --> 00:47:33,480
intrinsically typed evaluators
for a lambda calculi,

627
00:47:33,480 --> 00:47:35,600
or any kind of fancy
thing like that,

628
00:47:35,600 --> 00:47:40,160
which requires a list, where
the values stored in the list

629
00:47:40,160 --> 00:47:41,840
might actually have different types.

630
00:47:41,840 --> 00:47:43,480
And to do this in
a typesafe fashion,

631
00:47:43,480 --> 00:47:47,720
you typically use something called
a heterogeneous list or a H list.

632
00:47:47,720 --> 00:47:51,280
So this paper asked the question,
can we have our cake and eat it?

633
00:47:51,280 --> 00:47:52,600
Can we define a data structure

634
00:47:52,600 --> 00:47:55,840
that's both heterogeneous
and efficient?

635
00:47:55,840 --> 00:47:58,560
And this isn't just
a theoretical probe.

636
00:47:58,560 --> 00:48:02,120
So people who work in
industry and academia,

637
00:48:02,120 --> 00:48:05,200
such as David Christian, and
his co-authors at Galois,

638
00:48:05,200 --> 00:48:06,680
they wrote an experience report

639
00:48:06,680 --> 00:48:09,560
on Dependently Typed Haskell
in Industry last year,

640
00:48:09,560 --> 00:48:13,040
that they have this experience of
profiling crucible that showed

641
00:48:13,040 --> 00:48:17,920
that linear access imposed an unacceptable
overhead on the simulator.

642
00:48:17,920 --> 00:48:20,040
As a result, they actually
abandoned the typesafe

643
00:48:20,040 --> 00:48:22,760
dependently typed approach
that they were taking,

644
00:48:22,760 --> 00:48:26,840
in favor of data dot map
and an unsafe course.

645
00:48:26,840 --> 00:48:29,840
So what's in the paper? So
I show how to implement

646
00:48:29,840 --> 00:48:33,120
an heterogeneous binary
random access list in Agda.

647
00:48:33,120 --> 00:48:36,800
And this has the same API as just
regular heterogeneous list.

648
00:48:36,800 --> 00:48:39,680
So there's an empty structure, nil,

649
00:48:39,680 --> 00:48:41,480
and there's an operation
to add new elements

650
00:48:41,480 --> 00:48:44,560
to the front of the list
and operation to access elements

651
00:48:44,560 --> 00:48:47,120
within those two lookup,
or a bang, bang.

652
00:48:47,120 --> 00:48:50,200
And all of these operations
are both total and typesafe.

653
00:48:50,200 --> 00:48:53,360
And furthermore, there are no
coercions or lemmas necessary

654
00:48:53,360 --> 00:48:58,200
for everything to type check. It's
intrinsically typed by design.

655
00:48:59,000 --> 00:49:01,520
So in this talk, I won't try
to cover the whole paper.

656
00:49:01,520 --> 00:49:04,040
But instead, I'll just focus
on the homogeneous case,

657
00:49:04,040 --> 00:49:05,880
where we have binary
random access list

658
00:49:05,880 --> 00:49:08,200
originally proposed
by Chris Okasaki,

659
00:49:08,200 --> 00:49:11,040
in his book on purely
functional data structures,

660
00:49:11,040 --> 00:49:13,240
and show how to
implement that in Agda,

661
00:49:13,240 --> 00:49:15,880
in a kind of total and typesafe way.

662
00:49:15,880 --> 00:49:20,120
And then the heterogeneous version
follows quite naturally from this.

663
00:49:20,120 --> 00:49:23,200
So if we need better than
linear access times,

664
00:49:23,200 --> 00:49:26,240
we need to shift from
lists to trees.

665
00:49:26,240 --> 00:49:29,320
And for the moment, let's
just make the assumption

666
00:49:29,320 --> 00:49:33,200
that we only ever have to store
two to the power of n elements.

667
00:49:33,200 --> 00:49:34,800
And that's very easy to do

668
00:49:34,800 --> 00:49:37,560
because we can store two to
the power of n elements

669
00:49:37,560 --> 00:49:40,640
in a perfectly balanced
binary tree of depth n.

670
00:49:40,640 --> 00:49:45,160
So here are a few examples of
perfectly balanced binary trees,

671
00:49:45,160 --> 00:49:48,320
where I'm going to draw black dots
for the leaf storing data,

672
00:49:48,320 --> 00:49:51,880
and white dots for
the nodes which store no data.

673
00:49:51,880 --> 00:49:53,640
If I want to write this in Agda,

674
00:49:53,640 --> 00:49:55,680
I can define a little
datatype for my trees

675
00:49:55,680 --> 00:49:59,400
indexed by natural number corresponding
to the depth of the tree.

676
00:49:59,400 --> 00:50:03,200
So I can have a leaf which
stores an element of type a

677
00:50:03,200 --> 00:50:04,360
and has depth zero,

678
00:50:04,360 --> 00:50:08,360
or I can have a node which has
two sub trees of equal length,

679
00:50:08,360 --> 00:50:12,880
and then return a tree
which is one deeper.

680
00:50:12,880 --> 00:50:15,960
Now if I want to kind of denote any
particular value in such a tree,

681
00:50:15,960 --> 00:50:19,040
I typically use a path
through that tree.

682
00:50:19,040 --> 00:50:23,240
The data type path here is just
isomorphic to a vector of booleans

683
00:50:23,240 --> 00:50:25,800
but it's nice to have
this separate data type.

684
00:50:25,800 --> 00:50:28,080
The idea is that this path
tells me for every node

685
00:50:28,080 --> 00:50:30,040
whether I should go left or right.

686
00:50:30,040 --> 00:50:31,760
And then I can define
a lookup operation

687
00:50:31,760 --> 00:50:34,280
which just follows that
path with the tree.

688
00:50:34,280 --> 00:50:36,200
going to the left subtree

689
00:50:36,200 --> 00:50:38,000
if the path starts with
the left constructor

690
00:50:38,000 --> 00:50:40,240
and the right subtree if it starts
with the right constructor.

691
00:50:40,760 --> 00:50:42,240
At the end of the path I know

692
00:50:42,240 --> 00:50:45,160
that I've hit a leaf and turn
the value stored there.

693
00:50:45,680 --> 00:50:47,600
The important thing to notice here

694
00:50:48,120 --> 00:50:51,080
is that the type indices ensure
that the depth of the tree

695
00:50:51,080 --> 00:50:52,680
and the length of the path coincide.

696
00:50:53,200 --> 00:50:56,480
So I can always return
a value of type a.

697
00:50:57,240 --> 00:51:01,240
Now if I only have to store
2 to the power of n elements

698
00:51:01,240 --> 00:51:02,560
this would be the end of the talk.

699
00:51:03,040 --> 00:51:05,320
But you'd be very
right to complain that

700
00:51:05,320 --> 00:51:08,680
I can't just assume that
everything is a power of 2.

701
00:51:09,440 --> 00:51:11,240
But there is one
observation I can make

702
00:51:11,720 --> 00:51:14,440
which is that any number
can be written as a sum

703
00:51:14,440 --> 00:51:17,280
of powers of two using it's
binary representation.

704
00:51:17,800 --> 00:51:22,120
And that's the key idea behind
this binary random access list.

705
00:51:22,880 --> 00:51:25,040
So binary random
access list consists

706
00:51:25,040 --> 00:51:28,320
of the list of perfectly
balanced binary trees

707
00:51:28,320 --> 00:51:29,320
of increasing depths.

708
00:51:29,320 --> 00:51:30,880
And the ith position in this list

709
00:51:30,880 --> 00:51:34,880
there may or there may not be
a perfect binary tree of depth i.

710
00:51:35,400 --> 00:51:36,880
So let's look at some examples.

711
00:51:36,880 --> 00:51:39,240
So if I need to store three elements

712
00:51:39,240 --> 00:51:41,080
in a binary random access list.

713
00:51:41,080 --> 00:51:46,080
I can do this with a leaf followed
by a binary tree of depth one.

714
00:51:47,000 --> 00:51:50,880
If I need four elements,
I omit the first two tree

715
00:51:50,880 --> 00:51:52,920
but I have a tree of depth two.

716
00:51:53,440 --> 00:51:55,920
If I need five elements
I have a leaf,

717
00:51:56,400 --> 00:51:58,240
I have no tree in position two

718
00:51:58,240 --> 00:52:02,040
and I have a tree of depth two in
the second position in the list.

719
00:52:03,280 --> 00:52:05,880
I guess if you are familiar
with binary numbers

720
00:52:05,880 --> 00:52:07,080
you can see how this one works.

721
00:52:09,080 --> 00:52:13,080
So the number's
representation in binary

722
00:52:13,080 --> 00:52:15,800
determines the shape of
the binary random access list

723
00:52:15,800 --> 00:52:17,120
storing that many elements.

724
00:52:17,120 --> 00:52:18,320
So it'll need some binary numbers.

725
00:52:18,320 --> 00:52:19,800
Let's right that in Agda.

726
00:52:19,800 --> 00:52:22,080
So we can have a simple
type for binary numbers,

727
00:52:22,800 --> 00:52:25,000
0s and 1s and the end of the binary.

728
00:52:26,240 --> 00:52:28,400
We can define a successor operation

729
00:52:28,400 --> 00:52:29,800
which increments the binary number.

730
00:52:30,280 --> 00:52:33,560
The important thing here is that
we have the least significant bit

731
00:52:34,320 --> 00:52:35,800
at the beginning of
the binary number.

732
00:52:35,800 --> 00:52:37,680
So if we see a 0

733
00:52:37,680 --> 00:52:38,720
we can flip it to one,

734
00:52:38,720 --> 00:52:41,640
if we see a one we flip
it to a 0 and recurse.

735
00:52:42,880 --> 00:52:46,160
So now we can finally define
our random access list.

736
00:52:46,160 --> 00:52:48,760
There are three type arguments
that you can see here.

737
00:52:49,520 --> 00:52:52,880
The type A corresponding
to the type of the values

738
00:52:52,880 --> 00:52:54,320
stored in the random access list.

739
00:52:54,800 --> 00:52:57,680
The number N which is
the depth of the list

740
00:52:57,680 --> 00:52:59,720
as we are going down
and a binary number

741
00:52:59,720 --> 00:53:02,280
which kind of represents
the shape of the list

742
00:53:03,280 --> 00:53:04,600
of the random access list

743
00:53:04,600 --> 00:53:07,520
but it also kind of counts
the number of elements in this list.

744
00:53:08,800 --> 00:53:10,080
So there are three constructors.

745
00:53:10,080 --> 00:53:12,680
So nil is the end of the list

746
00:53:12,680 --> 00:53:15,880
and the kind of, corresponds
the empty binary word.

747
00:53:16,640 --> 00:53:20,720
If we are kind of using a one

748
00:53:21,240 --> 00:53:23,320
if the binary number
starts with a one

749
00:53:23,320 --> 00:53:26,680
we have a tree of depth n and a tail

750
00:53:26,680 --> 00:53:29,600
which kind of, it has
a shape of kind of binary

751
00:53:29,600 --> 00:53:31,800
of the remainder of
the tail of the binary word.

752
00:53:32,800 --> 00:53:35,320
And if the binary word
starts with a zero

753
00:53:35,800 --> 00:53:38,000
then we have no tree
but we have kind of a tail

754
00:53:38,000 --> 00:53:39,360
of the random access list

755
00:53:39,360 --> 00:53:40,600
that we might still have.

756
00:53:41,840 --> 00:53:44,160
So the binary number, counts
the number of elements

757
00:53:44,160 --> 00:53:46,240
and determines the shape of
our random access list.

758
00:53:46,720 --> 00:53:48,960
And one thing which you can see here

759
00:53:48,960 --> 00:53:51,640
is that the number n grows
as we go down the list.

760
00:53:51,640 --> 00:53:54,040
And this is not what you
might be familiar with

761
00:53:54,520 --> 00:53:56,280
if you reduce
the things like vectors

762
00:53:56,280 --> 00:53:58,560
or the vector, a little
number kind of counts down

763
00:53:58,560 --> 00:53:59,560
to the end of the list.

764
00:54:00,080 --> 00:54:02,280
Here n counts up as
we go down the list

765
00:54:02,280 --> 00:54:04,480
because they are kind of
increasingly deeper trees

766
00:54:04,480 --> 00:54:05,480
as we go down the list.

767
00:54:06,240 --> 00:54:08,240
And typically we consider
random access lists

768
00:54:08,240 --> 00:54:09,640
starting with the n zero

769
00:54:10,360 --> 00:54:12,720
but it's good to be a little
bit more general sometimes.

770
00:54:14,720 --> 00:54:17,280
So now we can define
a data for positions

771
00:54:17,280 --> 00:54:18,520
in a look up function.

772
00:54:18,520 --> 00:54:21,440
And these positions they are
kind of take a natural number

773
00:54:21,440 --> 00:54:23,680
in a binary number.

774
00:54:24,480 --> 00:54:25,920
And these positions kind of

775
00:54:25,920 --> 00:54:30,600
they essentially combine the usual
kind of linear position in a list

776
00:54:30,600 --> 00:54:32,200
and the path in a tree.

777
00:54:32,200 --> 00:54:35,160
So if we know that the binary number

778
00:54:35,160 --> 00:54:37,720
corresponds to the shape
of their own access list

779
00:54:37,720 --> 00:54:40,440
that we are accessing,
starts with a one,

780
00:54:40,440 --> 00:54:44,720
then we can choose to have
a path of length n in the tree

781
00:54:44,720 --> 00:54:45,720
at the head of the list.

782
00:54:46,480 --> 00:54:48,080
That's what the here
constructor does.

783
00:54:48,080 --> 00:54:50,040
The other two constructors there,

784
00:54:50,040 --> 00:54:52,840
they basically jump
over any kind of tree

785
00:54:52,840 --> 00:54:54,560
which may or may not be there

786
00:54:54,560 --> 00:54:56,400
and the kind of out most
list in the structure

787
00:54:56,880 --> 00:54:58,960
until we find the tree
that we are looking for

788
00:54:58,960 --> 00:55:00,360
and then we have the path

789
00:55:00,360 --> 00:55:02,600
in that tree to one of
the individual elements.

790
00:55:03,840 --> 00:55:06,080
And then we can define
a look up

791
00:55:06,080 --> 00:55:08,680
function in kind of
quite a straightforward now.

792
00:55:10,160 --> 00:55:12,240
If we want to add new
elements to this,

793
00:55:12,240 --> 00:55:13,320
this is a little bit tricky.

794
00:55:13,320 --> 00:55:17,600
The first thing you might try
would be to define a cons function

795
00:55:17,600 --> 00:55:18,640
which takes an A,

796
00:55:18,640 --> 00:55:20,800
which takes a random access list

797
00:55:20,800 --> 00:55:22,600
starting with depth zero

798
00:55:22,600 --> 00:55:25,720
and then produces
a new random access list

799
00:55:25,720 --> 00:55:27,240
where we have one more element.

800
00:55:27,240 --> 00:55:30,960
So we kind of implemented
the number of elements

801
00:55:30,960 --> 00:55:33,320
which is represented by
the binary number B.

802
00:55:34,520 --> 00:55:36,760
But if we try this we
get stuck quite quickly.

803
00:55:37,760 --> 00:55:40,200
As we kind of need to
make a recursive call,

804
00:55:40,680 --> 00:55:42,680
the tail of the binary random
access list

805
00:55:42,680 --> 00:55:45,360
actually has larger access trees in
which we are trying to add an A

806
00:55:45,360 --> 00:55:47,800
which kind of no longer
lines up some how.

807
00:55:48,800 --> 00:55:52,560
So the solution is to define kind
of a more general operation,

808
00:55:52,560 --> 00:55:55,360
a cons tree operations
which adds a tree of depth n

809
00:55:55,360 --> 00:55:57,520
to a random access list

810
00:55:58,800 --> 00:56:02,760
starting with n and then increments
the number of elements stored.

811
00:56:03,520 --> 00:56:06,120
And then we have the degenerate case

812
00:56:07,600 --> 00:56:11,000
where n equals 0 then it
corresponds to the cons operation

813
00:56:11,000 --> 00:56:12,000
that we have there.

814
00:56:12,760 --> 00:56:15,880
If you want to know a little bit more
about, the details are in the paper

815
00:56:15,880 --> 00:56:18,440
but the cons tree
operation closely mimics

816
00:56:18,440 --> 00:56:21,120
the kind of successor
operation on binary numbers.

817
00:56:22,600 --> 00:56:23,880
So to wrap up a little bit,

818
00:56:23,880 --> 00:56:25,920
we can extend this to
the heterogeneous case

819
00:56:25,920 --> 00:56:28,920
by writing a heterogeneous
binary random access list

820
00:56:28,920 --> 00:56:31,080
indexed by a random access list

821
00:56:31,080 --> 00:56:34,000
which stores some type information
for some universe u.

822
00:56:35,000 --> 00:56:37,320
And despite like
the apparent complexity,

823
00:56:37,800 --> 00:56:39,200
there is an example in the paper

824
00:56:39,200 --> 00:56:41,680
where I write an efficient
lambda calculus evaluator

825
00:56:41,680 --> 00:56:44,400
using heterogeneous binary
random access lists.

826
00:56:44,920 --> 00:56:47,040
And this turns out to be
no harder than just using

827
00:56:47,040 --> 00:56:48,560
kind of heterogeneous list

828
00:56:48,560 --> 00:56:50,560
that you would use in the usual situation.

829
00:56:51,320 --> 00:56:54,240
Furthermore it's fairly easy
to port this code to Haskell.

830
00:56:54,240 --> 00:56:57,120
It turns out that you only
need about 130 lines

831
00:56:57,120 --> 00:57:00,200
to define the data
structure of the nil,

832
00:57:00,200 --> 00:57:02,000
the cons and the look up operations

833
00:57:03,520 --> 00:57:05,680
of which I should point
out that maybe ten percent

834
00:57:05,680 --> 00:57:07,400
is language extension pragmas

835
00:57:07,400 --> 00:57:10,640
but there is nothing too
fancy going on there.

836
00:57:11,640 --> 00:57:14,720
So in conclusion if you can
choose the right data structure,

837
00:57:14,720 --> 00:57:17,960
one very nice thing about
these binary random access lists

838
00:57:17,960 --> 00:57:20,080
is that there is no
rotation involved.

839
00:57:20,080 --> 00:57:22,200
Everything kind of
stays in the same order

840
00:57:23,440 --> 00:57:27,680
regardless of when we add things
that kind of stays well formed.

841
00:57:28,400 --> 00:57:31,320
And if we choose our type
indices in such a way

842
00:57:31,320 --> 00:57:33,080
that we can enforce the key variance

843
00:57:33,080 --> 00:57:34,200
that we are interested in

844
00:57:34,200 --> 00:57:37,920
this ensures that all of our definitions
can go through quite cleanly

845
00:57:37,920 --> 00:57:40,920
and we really can have
our cake and eat it.

846
00:57:42,200 --> 00:57:47,160
(APPLAUSE)

847
00:57:49,720 --> 00:57:50,920
JEREMY: Thanks, Wouter.

848
00:57:51,400 --> 00:57:53,400
If you are watching the New
York streaming Clowdr,

849
00:57:53,400 --> 00:57:54,720
you should now see a Q&A link

850
00:57:54,720 --> 00:57:57,040
where you can ask Wouter
questions by video chat.

851
00:58:03,520 --> 00:58:05,600
The next talk is
the presentation of the paper

852
00:58:05,600 --> 00:58:09,040
POPLMark reloaded; Mechanizing
proofs by logical relations

853
00:58:10,040 --> 00:58:12,160
which presents a new collection
of benchmark problems

854
00:58:12,160 --> 00:58:14,600
in mechanizing the metatheory
of programming languages.

855
00:58:15,120 --> 00:58:17,800
The authors of
the papers are Andres Abel,

856
00:58:17,800 --> 00:58:22,960
Gias Allais, Alia Hameer, Brigitte
Pientka, Alberto Moenigliano

857
00:58:22,960 --> 00:58:25,120
Steven Schafer and Kathrine Stark.

858
00:58:25,120 --> 00:58:26,840
And Brigitte will be presenting.

859
00:58:30,840 --> 00:58:33,200
BRIGITTE PIENTKA: Hello
and welcome, thanks for coming.

860
00:58:33,200 --> 00:58:36,920
This talk is going to summarize
our JFP paper POPLMark reloaded

861
00:58:36,920 --> 00:58:38,920
mechanizing proofs by
logical relations.

862
00:58:39,400 --> 00:58:40,720
My name is Brigitte Pientka

863
00:58:40,720 --> 00:58:44,240
and this is joined work by
Andreas Andreas Abel, G. Allais,

864
00:58:44,240 --> 00:58:48,160
Alia Hameer, Alberto Moenigiliano,
Steven Schafer and Katherine Stark.

865
00:58:49,920 --> 00:58:53,080
So today mechanizations are
commonplace in programming languages.

866
00:58:53,600 --> 00:58:55,720
However they are also time consuming

867
00:58:55,720 --> 00:58:57,760
and there are few design guidelines.

868
00:58:59,000 --> 00:59:00,320
So what's the problem?

869
00:59:00,320 --> 00:59:02,880
The problem is that proofs
are tricky to write.

870
00:59:02,880 --> 00:59:06,040
Both on paper as well as
in proof assistants.

871
00:59:06,040 --> 00:59:08,600
There are a lot of challenging
details to keep track of.

872
00:59:08,600 --> 00:59:11,880
On paper it's hard to keep
track of dependencies

873
00:59:11,880 --> 00:59:14,400
among different theorems
and the definitions

874
00:59:14,400 --> 00:59:18,400
and you might think that proof
assistants are the answer.

875
00:59:18,920 --> 00:59:21,680
But in proof assistants there
is sort of another overhead

876
00:59:21,680 --> 00:59:22,880
we have to deal with.

877
00:59:22,880 --> 00:59:27,200
We have to build up the infrastructure
for modeling for example

878
00:59:27,200 --> 00:59:29,160
bindings and context and so on.

879
00:59:29,160 --> 00:59:32,320
So there is quite
a lot of time that gets

880
00:59:32,320 --> 00:59:34,120
into the building this
particular infrastructure.

881
00:59:34,640 --> 00:59:37,480
It's often hard to understand
how different features interact,

882
00:59:37,480 --> 00:59:40,720
difficulties increase with
the size of the mechanization

883
00:59:41,200 --> 00:59:43,160
and it can be really
quite time consuming.

884
00:59:43,160 --> 00:59:46,080
You see that often
a whole team of students

885
00:59:46,080 --> 00:59:49,000
is actually tacking some of
this mechanization efforts.

886
00:59:49,520 --> 00:59:51,520
And experience very much matters.

887
00:59:54,000 --> 00:59:57,960
Now the goal of this paper was
to develop a benchmark problem

888
00:59:57,960 --> 01:00:01,760
that would allow us to gain a deeper
understanding of the similarities

889
01:00:01,760 --> 01:00:05,840
and differences in how we mechanize
problems in programming languages

890
01:00:06,360 --> 01:00:10,480
Now we as developers of proof
assistants and libraries

891
01:00:10,480 --> 01:00:13,000
wanted to make our
approaches more robust

892
01:00:13,000 --> 01:00:15,080
and identify primitives
and abstractions

893
01:00:15,080 --> 01:00:17,400
to better structure
proofs and bring down

894
01:00:17,400 --> 01:00:19,080
the cost of verification overall.

895
01:00:21,080 --> 01:00:24,520
So it's worthwhile to take
a look back at POPLMark in 2005.

896
01:00:25,520 --> 01:00:30,120
Back in 2005 POPLMark challenge
was to mechanize system Fsub

897
01:00:30,640 --> 01:00:33,440
And that is a problem that can
be fairly easily understood.

898
01:00:33,440 --> 01:00:35,920
It's described in types and
programming languages,

899
01:00:36,680 --> 01:00:38,800
it can be mechanized in
a couple of hours.

900
01:00:38,800 --> 01:00:41,480
It focuses really on
representing and reasoning

901
01:00:41,480 --> 01:00:44,040
about structures with binders
in particular the model

902
01:00:44,520 --> 01:00:45,800
of the polymorphic functions space.

903
01:00:46,560 --> 01:00:49,320
All proofs are by syntactic
structural induction.

904
01:00:49,320 --> 01:00:52,320
And it was a great way of
exploring different encoding

905
01:00:52,320 --> 01:00:54,040
techniques for
representing bindings.

906
01:00:54,040 --> 01:00:57,600
In fact people used strings,
De Bruijn, nominal encodings,

907
01:00:57,600 --> 01:01:01,960
locally nameless as well
as higher order syntax.

908
01:01:03,240 --> 01:01:07,200
But on the flip side it did not
really identify any bugs or flaws

909
01:01:07,200 --> 01:01:08,400
in existing systems.

910
01:01:08,400 --> 01:01:11,320
It did not inspire the development
of new theoretical foundations

911
01:01:12,040 --> 01:01:14,600
nor did it push any existing
systems to their limit.

912
01:01:14,600 --> 01:01:17,680
All systems were in some
sense, equally suitable.

913
01:01:19,440 --> 01:01:21,960
So we wanted to go beyond
the POPLMark challenge.

914
01:01:21,960 --> 01:01:23,760
And in fact one doesn't
need to go very far,

915
01:01:23,760 --> 01:01:26,200
one just needs to look in
the conclusion of this paper

916
01:01:26,200 --> 01:01:28,640
and one sees that
one of the problems

917
01:01:28,640 --> 01:01:32,360
one challenges the authors mention
is Proof by Logical Relations.

918
01:01:33,600 --> 01:01:37,600
So our contribution here in this
paper is to describe a tutorial

919
01:01:37,600 --> 01:01:40,680
for strong normalization
proofs for well-typed terms

920
01:01:40,680 --> 01:01:42,680
using Kripke-style
logical relations.

921
01:01:43,200 --> 01:01:46,640
The really few standard
textbook chapters out there

922
01:01:46,640 --> 01:01:48,920
that focus on strong
formalization proofs.

923
01:01:49,920 --> 01:01:54,920
And although it has been really
a gold standard in some sense

924
01:01:55,520 --> 01:01:59,680
to evaluate proof assistants
using a strong normalization proof

925
01:01:59,680 --> 01:02:00,880
by logical relations.

926
01:02:01,400 --> 01:02:04,280
See for example there is
Altenkirch's work in 1993

927
01:02:05,800 --> 01:02:08,280
where he used Lego to
give a mechanization

928
01:02:08,280 --> 01:02:11,640
of a strong formalization proof
for simply-typed lambda calculus.

929
01:02:12,120 --> 01:02:16,920
Now one difference between
all this work and ours is that

930
01:02:16,920 --> 01:02:20,120
we are really focusing on
well-typed term representations

931
01:02:20,120 --> 01:02:23,400
and that leads us to
a Kripke-style logical relation

932
01:02:23,400 --> 01:02:26,600
where we talk about extensions
of typing contexts.

933
01:02:27,840 --> 01:02:30,680
And this also brings
me to the challenges

934
01:02:30,680 --> 01:02:34,200
which really go beyond
the original POPLMark challenge

935
01:02:34,200 --> 01:02:36,840
because we need to model
the simultaneous substitutions

936
01:02:36,840 --> 01:02:40,560
and renamings, context extensions,
structural properties

937
01:02:40,560 --> 01:02:43,480
such as weakening and exchange,
and strengthening play much more,

938
01:02:43,480 --> 01:02:47,880
central role and in order to
describe the reducibility definition

939
01:02:47,880 --> 01:02:50,520
we need to have a way
of distinguishing

940
01:02:50,520 --> 01:02:52,520
between inductive
and stratified definitions.

941
01:02:53,760 --> 01:02:56,280
And last we implemented
our solutions

942
01:02:56,280 --> 01:02:57,800
in three different proof assistance.

943
01:02:57,800 --> 01:02:59,160
Beluga, Coq and Agda.

944
01:03:01,440 --> 01:03:03,680
Now I also want to mention
some considerations

945
01:03:03,680 --> 01:03:06,360
that went into choosing this
particular bench mark

946
01:03:06,360 --> 01:03:08,320
because there are of course
many different kinds

947
01:03:08,320 --> 01:03:12,120
of logical relation proofs
and Kripke-style logical relational proof.

948
01:03:12,640 --> 01:03:15,640
In particular, there have been
very popular for reasoning

949
01:03:15,640 --> 01:03:18,000
about concurrent
and imperative programs

950
01:03:18,000 --> 01:03:21,040
where we reason about
memory extension

951
01:03:21,040 --> 01:03:22,960
rather than typing
context extensions.

952
01:03:23,680 --> 01:03:26,880
Nevertheless we focus here
on logical relations proofs

953
01:03:26,880 --> 01:03:27,960
for typed terms.

954
01:03:28,440 --> 01:03:31,240
in the simply-typed lambda calculus, no state.

955
01:03:31,240 --> 01:03:33,880
But we believe that this
is a good spring board

956
01:03:33,880 --> 01:03:35,480
for richer theories in particular

957
01:03:35,480 --> 01:03:36,600
dependent type theories.

958
01:03:36,600 --> 01:03:39,600
One problem in particular
that often comes up

959
01:03:39,600 --> 01:03:41,320
when you think about
dependant type theories is

960
01:03:42,080 --> 01:03:44,120
the notion of equality.

961
01:03:44,120 --> 01:03:47,160
And we need to sort of reason
about soundness and completeness

962
01:03:47,160 --> 01:03:49,480
of algorithmic type
directed equality.

963
01:03:49,480 --> 01:03:53,720
And the proof of soundness and completeness
of type directed equality

964
01:03:53,720 --> 01:03:57,400
exhibits many of the same
ideas and challenges

965
01:03:57,400 --> 01:04:00,480
that we have in the proof
of strong normalization

966
01:04:00,480 --> 01:04:02,040
of simply-typed lambda calculus.

967
01:04:03,280 --> 01:04:06,960
And last our guiding principle
was we need to design a benchmark

968
01:04:06,960 --> 01:04:10,320
that is reasonable so grad
students would be able to do it

969
01:04:10,320 --> 01:04:11,680
after reading the tutorial.

970
01:04:14,440 --> 01:04:16,640
So how do we define
strong normalization.

971
01:04:16,640 --> 01:04:20,720
So traditionally, we define it by
saying M is strongly normalizing

972
01:04:20,720 --> 01:04:25,080
if all rewrite sequences starting
in M end in a normal form.

973
01:04:25,080 --> 01:04:27,200
And this often characterized using

974
01:04:27,200 --> 01:04:29,320
what is called
an accessibility relation.

975
01:04:29,800 --> 01:04:33,280
But in fact the proof become
increasingly annoying

976
01:04:33,280 --> 01:04:36,320
when we need to reason about all
these different rewrite sequences

977
01:04:36,320 --> 01:04:38,440
and analyze different reducts.

978
01:04:40,160 --> 01:04:43,400
So the alternative was
proposed by a F van Raamsdonk

979
01:04:43,400 --> 01:04:46,440
and Paula Severi going
back also to (INAUDIBLE)

980
01:04:46,440 --> 01:04:49,040
this kind of modular approach
for strongly normalizing

981
01:04:49,800 --> 01:04:52,880
where we have inductive
characterizations in normal forms.

982
01:04:53,360 --> 01:04:55,200
And this leads to modular proofs

983
01:04:55,200 --> 01:04:57,160
both on paper
and mechanizations and the proofs

984
01:04:57,160 --> 01:04:58,760
essentially becomes much similar.

985
01:04:59,760 --> 01:05:02,720
So the first challenge problem
is to prove the equivalence

986
01:05:02,720 --> 01:05:06,320
between the accessibility relation
and inductive definition

987
01:05:06,320 --> 01:05:07,840
of strong normalizing terms.

988
01:05:08,360 --> 01:05:11,400
And the second one is actually
proving strong normalization

989
01:05:11,400 --> 01:05:14,800
for simply typed lambda calculus
using the inductive definition.

990
01:05:15,560 --> 01:05:17,640
And that will have
certain subproblems

991
01:05:17,640 --> 01:05:19,880
that will also be
described in the paper

992
01:05:19,880 --> 01:05:20,880
and outlined the proofs.

993
01:05:22,400 --> 01:05:26,440
So in the remaining few minutes
I want to talk about our solutions

994
01:05:26,440 --> 01:05:29,520
of one Beluga which uses
contextual higher order syntax

995
01:05:29,520 --> 01:05:33,080
and then Adga and Coq where we
use De Bruijn encodings.

996
01:05:35,080 --> 01:05:37,280
So Beluga is probably
the youngest system

997
01:05:37,280 --> 01:05:38,960
of these three proof assistance.

998
01:05:38,960 --> 01:05:42,440
It supports higher-order syntax based on
the logic of framework LF

999
01:05:42,440 --> 01:05:46,040
and therefore is of course
great to model binding structures.

1000
01:05:46,520 --> 01:05:48,960
Beluga also has build in
support for substitutions

1001
01:05:48,960 --> 01:05:50,560
and renamings and in that sense

1002
01:05:50,560 --> 01:05:53,120
it's kind of ideally suited
for that particular problem.

1003
01:05:53,880 --> 01:05:56,560
But it was also a great case
study for finding bugs

1004
01:05:56,560 --> 01:05:57,920
and making the system more robust.

1005
01:05:57,920 --> 01:06:00,600
In particular it allowed us to
find bugs in coverage checking

1006
01:06:00,600 --> 01:06:02,960
and extend termination checking.

1007
01:06:02,960 --> 01:06:05,240
And over the last year,
we also implemented

1008
01:06:05,240 --> 01:06:07,760
an interactive proof
development mode Harpoon

1009
01:06:07,760 --> 01:06:10,480
to make it easier to develop
such proofs in general.

1010
01:06:10,960 --> 01:06:12,800
But there is no proof automation.

1011
01:06:13,560 --> 01:06:16,280
Now Coq on the other hand we used

1012
01:06:16,280 --> 01:06:18,840
de Bruijn encodings
for modeling bindings.

1013
01:06:19,840 --> 01:06:21,680
We have in fact two solutions

1014
01:06:21,680 --> 01:06:23,720
developed by Katherine
Stark and Stephen Schafer.

1015
01:06:24,720 --> 01:06:26,880
The first one was on
well-scoped syntax

1016
01:06:26,880 --> 01:06:29,520
and the boilerplate was
generated by Autosubst 2.

1017
01:06:30,000 --> 01:06:33,720
And the second solution focus on
well-typed de Bruijn encodings

1018
01:06:33,720 --> 01:06:36,200
and the boilerplate sort
of proven manually.

1019
01:06:37,440 --> 01:06:40,120
Both proofs were a sort
of very much developed

1020
01:06:40,120 --> 01:06:43,400
in close collaboration with
our proofs in Beluga.

1021
01:06:43,400 --> 01:06:45,200
So they have a very
similar structure.

1022
01:06:45,720 --> 01:06:47,680
So everything can be
proven as expected.

1023
01:06:48,440 --> 01:06:50,640
It's very worthwhile nothing that
substitutions and weakenings

1024
01:06:50,640 --> 01:06:54,000
are functions mapping
from positions to terms

1025
01:06:54,000 --> 01:06:55,880
or positions to other positions.

1026
01:06:55,880 --> 01:06:58,560
And repetitive proofs
are kind of factored out

1027
01:06:58,560 --> 01:07:01,480
using proof scripts
and Coq tactics.

1028
01:07:02,720 --> 01:07:06,200
It also led to a way of
maybe rethinking Autosubst.

1029
01:07:06,200 --> 01:07:08,400
Maybe one should have an Autosubst 3

1030
01:07:08,400 --> 01:07:11,600
where we actually can
generate boilerplate code

1031
01:07:11,600 --> 01:07:13,440
for well-typed
syntax automatically.

1032
01:07:14,680 --> 01:07:17,960
And last Agda, we used the
generic syntax library

1033
01:07:17,960 --> 01:07:19,240
from (INAUDIBLE)

1034
01:07:19,240 --> 01:07:22,960
It worked very well for him as
an expert user to test

1035
01:07:22,960 --> 01:07:24,560
and stress test his

1036
01:07:25,720 --> 01:07:27,520
library,
it led for example

1037
01:07:27,520 --> 01:07:29,440
to implementing additional
generic results

1038
01:07:29,440 --> 01:07:33,560
as part of the generic-syntax
library because they were missing.

1039
01:07:33,560 --> 01:07:35,760
And the abstractions
provided by the library

1040
01:07:35,760 --> 01:07:37,720
led to very compact proofs.

1041
01:07:37,720 --> 01:07:39,560
Now, the theory of
renaming and substitution

1042
01:07:39,560 --> 01:07:44,320
is however not internalized
and there is no automation.

1043
01:07:44,320 --> 01:07:48,320
So overall, I think all of us
felt it was a success.

1044
01:07:48,320 --> 01:07:51,160
These benchmarks did expose
bugs and shortcomings

1045
01:07:51,160 --> 01:07:52,520
in existing systems.

1046
01:07:52,520 --> 01:07:54,800
It made libraries
and systems more robust.

1047
01:07:54,800 --> 01:07:57,200
It helped us restructure
our proofs,

1048
01:07:57,200 --> 01:07:59,920
and it helped us to gain a deeper
understanding of each approach

1049
01:07:59,920 --> 01:08:02,480
and how they're actually related.

1050
01:08:02,480 --> 01:08:04,080
So benchmarks can be great.

1051
01:08:04,080 --> 01:08:07,120
We would encourage
you to explore them.

1052
01:08:07,120 --> 01:08:09,280
Hopefully we'll see
a solution from you.

1053
01:08:09,280 --> 01:08:13,240
We already saw a solution developed
in F star, which is wonderful.

1054
01:08:13,240 --> 01:08:17,240
But we also hope that some of
the considerations and discussions

1055
01:08:17,240 --> 01:08:20,360
that led to the choice of
our benchmark problem

1056
01:08:20,360 --> 01:08:23,120
helps you to formulate
other challenge problems.

1057
01:08:23,120 --> 01:08:25,480
Of course, this isn't the end.

1058
01:08:25,480 --> 01:08:27,760
So thanks for listening.

1059
01:08:27,760 --> 01:08:34,680
(APPLAUSE)

1060
01:08:35,560 --> 01:08:37,760
JEREMY: Thanks Brigitte.

1061
01:08:37,760 --> 01:08:39,760
If you're watching the
New York streaming Clowdr,

1062
01:08:39,760 --> 01:08:41,440
you should not see a Q&A link

1063
01:08:41,440 --> 01:08:45,280
where you can ask Brigitte
questions by video chat.

1064
01:08:50,080 --> 01:08:52,640
The next talk is
a presentation of the paper,

1065
01:08:52,640 --> 01:08:55,640
perturbation confusion in forward
automatic differentiation

1066
01:08:55,640 --> 01:08:57,440
of higher-order functions,

1067
01:08:57,440 --> 01:08:59,000
which describes a longstanding bug

1068
01:08:59,000 --> 01:09:02,320
in the implementations of these
and two potential solutions.

1069
01:09:02,320 --> 01:09:06,480
The authors of the paper are
Oleksandr Manzyuk, Barak Pearlmutter,

1070
01:09:06,480 --> 01:09:09,760
Alexey Radul, David Rush,
and Jeﬀrey Mark Siskind.

1071
01:09:09,760 --> 01:09:13,520
And Barak will be presenting.

1072
01:09:14,120 --> 01:09:15,920
BARAK PEARLMUTTER: My name
is Barak Pearlmutter,

1073
01:09:15,920 --> 01:09:19,600
and I'd like to tell you about
a bug that we encountered

1074
01:09:19,600 --> 01:09:24,120
in allowing derivatives of
higher-order functions.

1075
01:09:24,120 --> 01:09:25,800
This work is part of
a sustained effort

1076
01:09:25,800 --> 01:09:27,280
to make automatic differentiation

1077
01:09:27,280 --> 01:09:30,520
robust, performant, general,
and ultimately ubiquitous,

1078
01:09:30,520 --> 01:09:32,080
and of course, correct.

1079
01:09:32,080 --> 01:09:33,960
It should be as easy to
take a derivative

1080
01:09:33,960 --> 01:09:36,680
as it is to take a square
root or write a loop.

1081
01:09:36,680 --> 01:09:38,600
That means programmers should
be able to take derivatives

1082
01:09:38,600 --> 01:09:41,000
of anything whose
derivative make sense.

1083
01:09:41,000 --> 01:09:43,200
So derivatives of functions,

1084
01:09:43,200 --> 01:09:47,560
which themselves take
or return functions,

1085
01:09:47,560 --> 01:09:51,320
like solving an ODE
or the derivative of map.

1086
01:09:51,320 --> 01:09:54,080
And of course, we want to take
derivatives of functions

1087
01:09:54,080 --> 01:09:55,960
which internally take derivatives.

1088
01:09:55,960 --> 01:09:58,920
So we want to allow nesting.

1089
01:09:59,560 --> 01:10:01,600
Let me set up what we need
to explore this issue.

1090
01:10:01,600 --> 01:10:03,360
I'll review our notation
and terminology

1091
01:10:03,360 --> 01:10:05,160
for forward automatic
differentiation.

1092
01:10:05,160 --> 01:10:07,280
Although the same issue
crops up in all other modes,

1093
01:10:07,280 --> 01:10:09,280
we'll use forward for clarity.

1094
01:10:09,280 --> 01:10:11,440
Then I'll talk about classic
perturbation confusion

1095
01:10:11,440 --> 01:10:13,320
and how it's avoided using tags.

1096
01:10:13,320 --> 01:10:15,200
We'll think about derivatives
of higher-order functions

1097
01:10:15,200 --> 01:10:17,840
and see how allowing them breaks
the one-to-one correspondence

1098
01:10:17,840 --> 01:10:20,680
between invoking derivative
operators and taking derivatives,

1099
01:10:20,680 --> 01:10:22,280
thus allowing this bug.

1100
01:10:22,280 --> 01:10:26,040
After that's all unpacked,
we'll look at ways to address the problem.

1101
01:10:26,040 --> 01:10:27,720
In forward automatic
differentiation,

1102
01:10:27,720 --> 01:10:30,240
derivatives are piggybacked
on primal values.

1103
01:10:30,240 --> 01:10:32,720
So we have x plus x prime epsilon,

1104
01:10:32,720 --> 01:10:37,640
x is the primal, x prime is
the derivative value called a tangent.

1105
01:10:37,640 --> 01:10:41,960
This is a dual number,
like a complex number inside the computer,

1106
01:10:41,960 --> 01:10:45,240
it's represented as
a two element pair.

1107
01:10:45,240 --> 01:10:47,840
These are propagated according
to the rules of calculus,

1108
01:10:47,840 --> 01:10:51,040
and we have an operator for
extracting the epsilon coefficient,

1109
01:10:51,040 --> 01:10:53,120
the tangent of an output.

1110
01:10:53,120 --> 01:10:56,400
I'll show how this is used to perform
forward automatic differentiation

1111
01:10:56,400 --> 01:10:59,080
on a simple but topical function.

1112
01:10:59,080 --> 01:11:02,480
Let's say f of t is one over one
plus e to the minus t.

1113
01:11:02,480 --> 01:11:06,400
We define the operator D to take
the derivative of f at a point x

1114
01:11:06,400 --> 01:11:14,120
by feeding x plus epsilon into f
extracting the tangent of the output.

1115
01:11:14,120 --> 01:11:16,680
We can take f of two
to get 0.881,

1116
01:11:16,680 --> 01:11:18,880
and take the derivative of f at two,

1117
01:11:18,880 --> 01:11:21,600
take f of two plus epsilon,

1118
01:11:21,600 --> 01:11:26,560
crank that through,
we get 0.881 plus 0.105 epsilon.

1119
01:11:26,560 --> 01:11:31,600
We extract the tangent to
get the derivative of 0.105.

1120
01:11:31,600 --> 01:11:35,480
This function is also the solution
to Verhulst's epidemic equation.

1121
01:11:35,480 --> 01:11:37,200
The derivative is
the rate of infection.

1122
01:11:37,200 --> 01:11:41,800
So did you really think you could
go a whole talk without Coronavirus?

1123
01:11:41,800 --> 01:11:43,880
It used to be that
nesting was a niche idea,

1124
01:11:43,880 --> 01:11:46,360
but many applications
demand nesting.

1125
01:11:46,360 --> 01:11:47,960
When done in frameworks
that don't support it

1126
01:11:47,960 --> 01:11:51,000
programmers end up going through
all kinds of crazy hoops

1127
01:11:51,000 --> 01:11:52,080
to get nesting working.

1128
01:11:52,080 --> 01:11:53,520
Sed scripts to patch source code

1129
01:11:53,520 --> 01:11:55,680
between multiple passes
through preprocessors,

1130
01:11:55,680 --> 01:11:57,160
manual closure conversion,

1131
01:11:57,160 --> 01:11:59,880
all kinds of heroic technical
debt creating shenanigans.

1132
01:11:59,880 --> 01:12:02,280
We want it to be natural.

1133
01:12:02,920 --> 01:12:04,560
Here's some simple nesting.

1134
01:12:04,560 --> 01:12:08,080
D takes a derivative at a point.

1135
01:12:09,240 --> 01:12:12,320
On the left here is conventional
mathematical notation

1136
01:12:12,320 --> 01:12:13,480
for a nested derivative.

1137
01:12:13,480 --> 01:12:16,680
Notice how much nicer the functional
notation on the right is.

1138
01:12:16,680 --> 01:12:20,760
Regular calculus is better
with lambda calculus, right?

1139
01:12:20,760 --> 01:12:23,120
Look at the definition of D.

1140
01:12:23,120 --> 01:12:26,400
Now there's this fresh thing
that there wasn't before.

1141
01:12:26,400 --> 01:12:30,720
That means we get a fresh
epsilon every time we invoke D.

1142
01:12:30,720 --> 01:12:35,160
So that nested invocations
have different epsilon tags.

1143
01:12:35,160 --> 01:12:38,040
And so their tangents don't collide.

1144
01:12:38,040 --> 01:12:41,320
That's critical to
getting the right answer.

1145
01:12:41,320 --> 01:12:44,120
When I say epsilon i
or a different tag,

1146
01:12:44,120 --> 01:12:46,720
these might be implemented
in lots of different ways,

1147
01:12:46,720 --> 01:12:49,920
like by nested structures with
existential types for safety

1148
01:12:49,920 --> 01:12:51,560
or a variety of other techniques.

1149
01:12:51,560 --> 01:12:53,280
We're abstracting all that away

1150
01:12:53,280 --> 01:12:58,520
and just saying tag, different
epsilon tags, different indices.

1151
01:13:04,000 --> 01:13:07,240
Recent formulations often
still get this wrong.

1152
01:13:07,240 --> 01:13:09,760
For some of them it's out of scope,
you can't even express nesting.

1153
01:13:09,760 --> 01:13:14,720
For others they crash,
you get the wrong answer.

1154
01:13:14,720 --> 01:13:17,200
The phrase higher-order
automatic differentiation

1155
01:13:17,200 --> 01:13:19,560
is used in a bunch of different
senses in the literature.

1156
01:13:19,560 --> 01:13:22,720
When we use it here
we mean the hard one.

1157
01:13:22,720 --> 01:13:26,400
This first definition, taking
derivatives of higher-order functions,

1158
01:13:26,400 --> 01:13:28,600
not plain higher-order
derivatives,

1159
01:13:28,600 --> 01:13:30,560
and not derivatives of
first order functions

1160
01:13:30,560 --> 01:13:34,600
defined using
higher-order operators.

1161
01:13:35,080 --> 01:13:38,040
What is meant by the derivative
of a higher-order function?

1162
01:13:38,040 --> 01:13:40,440
Well, in part that
was the motivation

1163
01:13:40,440 --> 01:13:43,080
for the development of the whole
field of differential geometry

1164
01:13:43,080 --> 01:13:45,720
100s of years ago.

1165
01:13:46,440 --> 01:13:51,240
But let's give a simple example
of a binary curried function.

1166
01:13:51,240 --> 01:13:54,800
So f of x y equals x squared
plus blah, blah, blah.

1167
01:13:54,800 --> 01:13:59,080
We can take f at the point five
and get a function from y,

1168
01:13:59,080 --> 01:14:01,280
225 plus y squared, blah, blah, blah.

1169
01:14:01,280 --> 01:14:04,160
We take the derivative of f at five,

1170
01:14:04,160 --> 01:14:06,680
and we'll get
the partial derivative of f

1171
01:14:06,680 --> 01:14:09,040
with respect to its first argument.

1172
01:14:09,040 --> 01:14:12,680
So the map from y to the derivative
of that expression,

1173
01:14:12,680 --> 01:14:17,680
with respect to x at
the point x equals five and y.

1174
01:14:18,880 --> 01:14:22,080
I'm ignoring derivatives of functions
whose domain is a function.

1175
01:14:22,080 --> 01:14:24,760
Read the paper for that.

1176
01:14:24,760 --> 01:14:26,640
In order for this to go through,

1177
01:14:26,640 --> 01:14:28,680
we're going to have to extend
the derivative operator.

1178
01:14:28,680 --> 01:14:30,520
Well, not the derivative
operator itself

1179
01:14:30,520 --> 01:14:33,160
whose definition remains
the same, but it's type.

1180
01:14:33,160 --> 01:14:36,640
And also we have to extend
the tangent operator.

1181
01:14:37,800 --> 01:14:41,920
The tangent operator operates
on numbers the same way,

1182
01:14:41,920 --> 01:14:47,040
but on functions by
post-composition.

1183
01:14:47,040 --> 01:14:50,720
OK. Now we're in a position to
do something very disturbing

1184
01:14:50,720 --> 01:14:51,840
or quite amazing,

1185
01:14:51,840 --> 01:14:54,280
depending on whether you like to
build large correct artifacts

1186
01:14:54,280 --> 01:14:57,520
or enjoy watching slow
motion train wrecks.

1187
01:14:57,520 --> 01:14:59,680
So I'm going to define
an offset operator s,

1188
01:14:59,680 --> 01:15:02,120
it takes an offset u
and a function f

1189
01:15:02,120 --> 01:15:05,600
and returns f offset by u.

1190
01:15:05,600 --> 01:15:08,280
And I'm going to define D hat
to be the derivative of s

1191
01:15:08,280 --> 01:15:10,720
at the point zero.

1192
01:15:10,720 --> 01:15:15,760
If we look at D of f at x,
we expand things out, turn the crank,

1193
01:15:15,760 --> 01:15:17,160
and we get f prime of x.

1194
01:15:17,160 --> 01:15:20,640
Similarly, if we take
D hat of f at x,

1195
01:15:20,640 --> 01:15:24,760
we expand out the definition
of D hat, turn the crank,

1196
01:15:24,760 --> 01:15:26,560
and we get f prime of x.

1197
01:15:26,560 --> 01:15:30,080
So we should have D hat equals D.

1198
01:15:30,080 --> 01:15:32,560
But if we use them in
a nested fashion,

1199
01:15:32,560 --> 01:15:35,720
D is operating correctly
on a scalar function h

1200
01:15:35,720 --> 01:15:37,680
takes a second derivative,

1201
01:15:37,680 --> 01:15:41,080
but D hat gives us
a constant function zero

1202
01:15:41,080 --> 01:15:44,320
when used in this nested fashion.

1203
01:15:44,320 --> 01:15:45,760
What happened?

1204
01:15:45,760 --> 01:15:49,520
Well, the fresh triggered
when D was invoked,

1205
01:15:49,520 --> 01:15:55,120
the thing is D s of
zero returned a value

1206
01:15:55,120 --> 01:15:58,640
which has a single tag in it,
a single concrete tag.

1207
01:15:58,640 --> 01:16:02,360
So when it's nested,
we can get a collision.

1208
01:16:05,400 --> 01:16:08,160
That's really bad.

1209
01:16:08,760 --> 01:16:10,080
OK, all unpacked.

1210
01:16:10,080 --> 01:16:13,240
That's the dirty laundry of higher-order
automatic differentiation.

1211
01:16:13,240 --> 01:16:16,680
Now, let's get to
the bottom of this mess.

1212
01:16:17,520 --> 01:16:19,080
What's the root cause?

1213
01:16:19,080 --> 01:16:22,240
Note D was invoked once in
the definition of D hat,

1214
01:16:22,240 --> 01:16:24,040
but we can still get
nested derivatives.

1215
01:16:24,040 --> 01:16:25,960
And that's because derivatives
of higher-order functions

1216
01:16:25,960 --> 01:16:27,800
breaks the one-to-one relationship

1217
01:16:27,800 --> 01:16:32,440
between invoking a derivative
operator and taking a derivative.

1218
01:16:32,440 --> 01:16:35,080
It's like those corny jokes
about engineers and accountants

1219
01:16:35,080 --> 01:16:37,440
traveling with fewer tickets
than people are hiding in the loo

1220
01:16:37,440 --> 01:16:39,120
and the conductor comes
to check tickets.

1221
01:16:39,120 --> 01:16:42,520
There's a disconnect between allocating
the tags and using the tags.

1222
01:16:42,520 --> 01:16:46,240
And we have poor enforcement of
the one tag per nested derivative

1223
01:16:46,240 --> 01:16:49,400
calculation policy.

1224
01:16:50,440 --> 01:16:54,840
The key issue is that we need
to distinguish the tangents,

1225
01:16:54,840 --> 01:16:56,680
the tags for different derivatives,

1226
01:16:56,680 --> 01:17:00,120
even though the derivative
operator is called only once.

1227
01:17:00,120 --> 01:17:03,520
If we don't, we get
perturbation confusion.

1228
01:17:03,520 --> 01:17:05,240
Here's an idea for a workaround.

1229
01:17:05,240 --> 01:17:06,680
We would have gotten
the correct result

1230
01:17:06,680 --> 01:17:10,680
if D hat had been left un-reduced.

1231
01:17:12,160 --> 01:17:14,520
So, instead of writing that
expression at the bottom

1232
01:17:14,520 --> 01:17:16,160
where we use D hat twice,

1233
01:17:16,160 --> 01:17:19,880
we could define D hat twice
and use the two different definitions.

1234
01:17:19,880 --> 01:17:22,720
That would be OK,
except it's manual and horrible.

1235
01:17:22,720 --> 01:17:25,160
We want programmers to just take
derivatives and get the right answer

1236
01:17:25,160 --> 01:17:27,960
and not have to worry about
what's under the hood.

1237
01:17:27,960 --> 01:17:30,760
So here's an idea for accomplishing
this more transparently.

1238
01:17:30,760 --> 01:17:32,360
We could use eta expansion.

1239
01:17:32,360 --> 01:17:33,520
We would delay the fresh

1240
01:17:33,520 --> 01:17:36,640
until all the arguments needed
for post-composition of tangent

1241
01:17:36,640 --> 01:17:37,640
are available.

1242
01:17:37,640 --> 01:17:40,640
So immediately beta reduces to
a non-function containing value.

1243
01:17:40,640 --> 01:17:43,240
So we'd have separate versions of D

1244
01:17:43,240 --> 01:17:48,240
for scalar functions,
binary curried functions, etc.

1245
01:17:49,400 --> 01:17:53,120
This could also be accomplished
using polymorphic recursion,

1246
01:17:53,120 --> 01:17:56,400
although that gets hairy when
the underlying language

1247
01:17:56,400 --> 01:17:58,360
gets more complicated.

1248
01:17:58,360 --> 01:18:00,480
Here's another idea.

1249
01:18:00,480 --> 01:18:04,080
What's going wrong is that
the value passed into the function

1250
01:18:04,080 --> 01:18:05,880
whose tangent is being taken,

1251
01:18:05,880 --> 01:18:10,640
might have the same tag that's
in play in that function.

1252
01:18:10,640 --> 01:18:16,320
So we could augment it with a wrapper
to guard the tag in the function

1253
01:18:16,320 --> 01:18:18,080
so that if it occurs externally,

1254
01:18:18,080 --> 01:18:20,960
the external one gets renamed
away and then renamed back

1255
01:18:20,960 --> 01:18:24,400
after being passed through.

1256
01:18:24,400 --> 01:18:26,240
OK, take-home message.

1257
01:18:26,240 --> 01:18:28,240
We can import
the standard definitions

1258
01:18:28,240 --> 01:18:30,040
of derivatives of
higher-order functions

1259
01:18:30,040 --> 01:18:31,840
into automatic differentiation,

1260
01:18:31,840 --> 01:18:36,840
but allowing them breaks
the automatic differentiation machinery.

1261
01:18:37,560 --> 01:18:40,240
Now, it might be a stretch to
call this the amazing bug.

1262
01:18:40,240 --> 01:18:41,440
It's a pretty crowded field,

1263
01:18:41,440 --> 01:18:44,120
but I hope you'll agree
that it's an amazing bug.

1264
01:18:44,120 --> 01:18:47,160
We have some ideas for solving this.

1265
01:18:47,160 --> 01:18:49,600
And I proposes two
solution frameworks.

1266
01:18:49,600 --> 01:18:51,280
One is based on eta expansion,

1267
01:18:51,280 --> 01:18:55,920
and the other on renaming tags away
and then renaming them back

1268
01:18:55,920 --> 01:19:00,920
when they're passing through
the tangents of closures.

1269
01:19:03,600 --> 01:19:07,440
Recent formulations of forward
of automatic differentiation

1270
01:19:07,440 --> 01:19:09,240
still often get this wrong.

1271
01:19:09,240 --> 01:19:13,600
For some it's out of scope,
others get the wrong answer.

1272
01:19:13,600 --> 01:19:15,160
The two solutions that I proposed,

1273
01:19:15,160 --> 01:19:17,480
they solve the correctness issue

1274
01:19:17,480 --> 01:19:20,440
but they do have some issues
with complexity.

1275
01:19:20,440 --> 01:19:24,000
So we would like to
work on this some more

1276
01:19:24,000 --> 01:19:26,920
to get the efficiency right,
both constant factor efficiency,

1277
01:19:26,920 --> 01:19:30,240
and these solutions
implemented naively at least

1278
01:19:30,240 --> 01:19:34,280
would seem to break some of
the complexity guarantees

1279
01:19:34,280 --> 01:19:38,280
that we'd like to make
an automatic differentiation.

1280
01:19:38,280 --> 01:19:39,480
Thank you for listening.

1281
01:19:39,480 --> 01:19:41,000
I hope this story has
been of interest.

1282
01:19:41,000 --> 01:19:42,560
And I'd like to thank the organizers

1283
01:19:42,560 --> 01:19:44,880
for arranging this
fantastic virtual gathering

1284
01:19:44,880 --> 01:19:47,440
under very difficult circumstances.

1285
01:19:47,440 --> 01:19:49,840
I'd be happy to answer
any questions.

1286
01:19:49,840 --> 01:19:56,560
(APPLAUSE)

1287
01:19:58,040 --> 01:19:59,640
JEREMY: Thanks Barak.

1288
01:19:59,640 --> 01:20:01,920
If you're watching the
New York streaming Clowdr,

1289
01:20:01,920 --> 01:20:03,320
you can now see a Q&A link

1290
01:20:03,320 --> 01:20:07,280
where you can ask Barak
and Jeffrey questions by video chat.

1291
01:20:13,080 --> 01:20:15,520
The next talk is
a presentation of the paper

1292
01:20:15,520 --> 01:20:17,600
elastic sheet defined functions,

1293
01:20:17,600 --> 01:20:21,400
generalizing spreadsheet functions
to variable size input arrays,

1294
01:20:21,400 --> 01:20:24,120
which is about helping end-user
spreadsheet programmers

1295
01:20:24,120 --> 01:20:25,840
to write more flexible functions

1296
01:20:25,840 --> 01:20:29,000
that work over inputs
of arbitrary size.

1297
01:20:29,000 --> 01:20:32,600
The authors of the paper are
Matt McCutchen, Judith Borghouts,

1298
01:20:32,600 --> 01:20:36,280
Andy Gordon, Simon Peyton Jones
and Advait Sarkar.

1299
01:20:36,280 --> 01:20:38,960
And Matt will be presenting.

1300
01:20:38,960 --> 01:20:40,040
MATT MCCUTCHEN:
Hi, I'm Matt McCutchen

1301
01:20:40,040 --> 01:20:41,680
and I'm going to talk
about a method of

1302
01:20:41,680 --> 01:20:43,800
automatically generalizing
spreadsheet functions

1303
01:20:43,800 --> 01:20:45,800
to variable-size input arrays,

1304
01:20:45,800 --> 01:20:49,760
which we've nicknamed elastic
sheet-defined functions.

1305
01:20:49,760 --> 01:20:52,000
The spreadsheet is by far
the most widely used

1306
01:20:52,000 --> 01:20:55,040
functional programming environment
because it's so easy to use

1307
01:20:55,040 --> 01:20:58,040
even for people unfamiliar with
conventional programming.

1308
01:20:58,040 --> 01:21:00,200
For instance, suppose we're
shopping for a set of foods

1309
01:21:00,200 --> 01:21:02,240
and the prices are
given without tax.

1310
01:21:02,240 --> 01:21:05,440
We want to compute the total amount
we'll pay, including the tax.

1311
01:21:05,440 --> 01:21:07,480
We just type our starting
data into the cells

1312
01:21:07,480 --> 01:21:10,640
and enter the formulas we want
to calculate into other cells.

1313
01:21:10,640 --> 01:21:12,640
If it's too mind-bending
to calculate the tax

1314
01:21:12,640 --> 01:21:14,120
on all the foods at once,

1315
01:21:14,120 --> 01:21:17,280
we can do it for the apple
and then copy the formula.

1316
01:21:17,280 --> 01:21:20,040
We have to be a little careful with
relative and absolute referencing,

1317
01:21:20,040 --> 01:21:23,440
but if we make a mistake,
it's easy to spot and fix.

1318
01:21:23,440 --> 01:21:26,480
We can work one step at a time
and always see all the data at once.

1319
01:21:26,480 --> 01:21:30,840
So for a simple problem like this,
we never have to think very hard.

1320
01:21:30,840 --> 01:21:33,560
Now suppose we want to total
a lot of shopping lists.

1321
01:21:33,560 --> 01:21:37,080
Of course, rather than make many
independent copies of the formulas,

1322
01:21:37,080 --> 01:21:39,640
we'd like to reuse them so that
if we have to fix a bug

1323
01:21:39,640 --> 01:21:41,160
in the original formulas,

1324
01:21:41,160 --> 01:21:43,560
the fix takes effect on
all the shopping lists.

1325
01:21:43,560 --> 01:21:46,720
Since we're familiar with calling
built-in functions like SUM,

1326
01:21:46,720 --> 01:21:48,960
can we define our own function
for the shopping list

1327
01:21:48,960 --> 01:21:50,360
that we could call?

1328
01:21:50,360 --> 01:21:52,840
In current mainstream
spreadsheet tools, we can,

1329
01:21:52,840 --> 01:21:55,520
but we have to rewrite the logic in
a separate programming language

1330
01:21:55,520 --> 01:21:57,000
such as Visual Basic,

1331
01:21:57,000 --> 01:22:01,960
which sacrifices all the usability
advantages of spreadsheets.

1332
01:22:01,960 --> 01:22:03,440
Fortunately, there's
an easier approach

1333
01:22:03,440 --> 01:22:05,440
that has appeared in
many research systems,

1334
01:22:05,440 --> 01:22:08,520
and we think it's only a matter of
time before it becomes mainstream:

1335
01:22:08,520 --> 01:22:10,520
the sheet-defined function, or SDF.

1336
01:22:10,520 --> 01:22:13,400
To make our original
formulas into an SDF,

1337
01:22:13,400 --> 01:22:15,160
we just mark
the cells that represent

1338
01:22:15,160 --> 01:22:17,640
the inputs and output of
the function and give it a name.

1339
01:22:17,640 --> 01:22:19,560
Now we can call SHOP
on the second list,

1340
01:22:19,560 --> 01:22:22,240
just like a built-in function.

1341
01:22:22,240 --> 01:22:25,120
Semantically, the tool makes
a temporary copy of the function body

1342
01:22:25,120 --> 01:22:28,240
with our new inputs substituted in
and returns the new output,

1343
01:22:28,240 --> 01:22:30,800
but of course the tool can
optimize this process.

1344
01:22:30,800 --> 01:22:33,560
The user can open the temporary
sheet to see what happened.

1345
01:22:33,560 --> 01:22:35,600
This requires users to
think a little harder,

1346
01:22:35,600 --> 01:22:38,160
but we think many of them will
be comfortable defining SDFs,

1347
01:22:38,160 --> 01:22:42,080
and the rest will at least be
comfortable calling them.

1348
01:22:42,080 --> 01:22:43,720
However, we quickly
run into a problem

1349
01:22:43,720 --> 01:22:46,120
if we call SHOP on a shopping list
of a different length

1350
01:22:46,120 --> 01:22:47,360
than the original.

1351
01:22:47,360 --> 01:22:49,840
When we try to put the pre-tax
prices in the input range,

1352
01:22:49,840 --> 01:22:53,040
they'll get cut off
and we'll get the wrong answer.

1353
01:22:53,040 --> 01:22:55,120
The result we'd like is
as if the body of SHOP

1354
01:22:55,120 --> 01:22:57,000
were resized to fit the input.

1355
01:22:57,000 --> 01:23:00,040
How can we make SHOP
behave this way?

1356
01:23:00,040 --> 01:23:02,480
One approach is to let
the entire array of prices

1357
01:23:02,480 --> 01:23:04,120
be stored in a single cell.

1358
01:23:04,120 --> 01:23:06,600
If we apply an operator
like "+" to two arrays,

1359
01:23:06,600 --> 01:23:09,240
we're implicitly adding
the corresponding elements.

1360
01:23:09,240 --> 01:23:12,160
This will work regardless of
the sizes of the arrays.

1361
01:23:12,160 --> 01:23:13,840
This is a little more
for users to learn,

1362
01:23:13,840 --> 01:23:17,160
but it's a plausible
solution for SHOP.

1363
01:23:17,160 --> 01:23:18,760
However, for more complex SDFs,

1364
01:23:18,760 --> 01:23:21,520
the array programming approach
becomes unmanageable.

1365
01:23:21,520 --> 01:23:23,640
Here's a sheet containing
the transaction history

1366
01:23:23,640 --> 01:23:26,240
for a bank account with
interest compounded daily.

1367
01:23:26,240 --> 01:23:28,720
To compute the balance
after a transaction,

1368
01:23:28,720 --> 01:23:31,080
first we apply the interest
to the previous balance

1369
01:23:31,080 --> 01:23:34,200
based on the number of days
since the previous transaction.

1370
01:23:34,200 --> 01:23:37,080
Then we add the amount of
the current transaction.

1371
01:23:37,080 --> 01:23:39,040
This example presents
two new problems

1372
01:23:39,040 --> 01:23:41,120
for the array programming approach.

1373
01:23:41,120 --> 01:23:43,280
To line up the previous dates
with the current dates,

1374
01:23:43,280 --> 01:23:46,040
we need to shift the array
in A4 down one element

1375
01:23:46,040 --> 01:23:47,600
and add A3 at the top.

1376
01:23:47,600 --> 01:23:50,160
Let's assume that a spreadsheet tool
designed for array programming

1377
01:23:50,160 --> 01:23:52,440
will have a SHIFT_DOWN
function to do that.

1378
01:23:52,440 --> 01:23:54,680
But for the reference to
the previous balance,

1379
01:23:54,680 --> 01:23:56,440
if we tried to do the same thing,

1380
01:23:56,440 --> 01:23:58,920
we'd end up with the whole
array in C4 depending on itself

1381
01:23:58,920 --> 01:24:00,280
which won't work.

1382
01:24:00,280 --> 01:24:01,400
To handle the iteration,

1383
01:24:01,400 --> 01:24:03,800
we need to use a special
function called VSCAN2

1384
01:24:03,800 --> 01:24:04,840
and pass a lambda function

1385
01:24:04,840 --> 01:24:07,400
that computes each element
from the previous one.

1386
01:24:07,400 --> 01:24:09,160
Most users won't be able
to come up with this

1387
01:24:09,160 --> 01:24:11,480
unless they find an example on
the web that's similar enough

1388
01:24:11,480 --> 01:24:14,880
that they can adapt
it to their problem.

1389
01:24:14,880 --> 01:24:17,160
If that isn't bad enough,
here's another SDF

1390
01:24:17,160 --> 01:24:18,160
with a naive model

1391
01:24:18,160 --> 01:24:20,360
of cascading delays in
a bus transit system.

1392
01:24:20,880 --> 01:24:22,640
The idea is that
a departure from a station

1393
01:24:22,640 --> 01:24:24,320
will be delayed if
the bus that was supposed

1394
01:24:24,320 --> 01:24:26,560
to make the trip hasn't arrived yet.

1395
01:24:26,560 --> 01:24:29,480
We want this SDF to resize
in three different

1396
01:24:29,480 --> 01:24:31,360
ways: the number of time
steps in the simulation

1397
01:24:31,360 --> 01:24:33,720
in the vertical direction,
and the numbers of stations

1398
01:24:33,720 --> 01:24:35,880
and routes both in
the horizontal direction.

1399
01:24:36,400 --> 01:24:39,200
There's mutual recursion
among four of the arrays.

1400
01:24:39,200 --> 01:24:40,720
While we think this
is possible to write

1401
01:24:40,720 --> 01:24:41,720
using array programming,

1402
01:24:41,720 --> 01:24:43,800
it's going to be such a mess
that I won't even try.

1403
01:24:45,840 --> 01:24:47,120
So it seems we really do want

1404
01:24:47,120 --> 01:24:49,160
to resize an SDF at the cell level,

1405
01:24:49,160 --> 01:24:51,320
effectively generalizing
it to handle inputs

1406
01:24:51,320 --> 01:24:54,800
of variable size;
we call the result an elastic SDF.

1407
01:24:54,800 --> 01:24:56,280
Maybe the user could somehow

1408
01:24:56,280 --> 01:24:58,120
specify how
the resizing should work.

1409
01:24:58,120 --> 01:25:00,000
But it turns out that for many SDFs,

1410
01:25:00,000 --> 01:25:01,760
including all three
we've seen so far,

1411
01:25:01,760 --> 01:25:03,320
the user doesn't need to do anything

1412
01:25:03,320 --> 01:25:05,880
because we can figure out
the resizing automatically.

1413
01:25:05,880 --> 01:25:07,560
That's the topic of our paper.

1414
01:25:09,040 --> 01:25:11,400
Let's see how
the generalization process works

1415
01:25:11,400 --> 01:25:13,000
in the simpler SHOP example.

1416
01:25:13,000 --> 01:25:14,840
For the purpose of
describing our work,

1417
01:25:14,840 --> 01:25:17,080
we use a textual
notation for SDFs.

1418
01:25:17,080 --> 01:25:19,520
Users don't need to know anything
about this notation,

1419
01:25:19,520 --> 01:25:22,440
though we have evidence that
some users may find it helpful.

1420
01:25:22,440 --> 01:25:25,560
Here we have the function name
and the input and output ranges.

1421
01:25:25,560 --> 01:25:28,040
Each line of the body
describes a rectangular tile

1422
01:25:28,040 --> 01:25:30,440
of one or more cells with
a copied formula.

1423
01:25:30,440 --> 01:25:33,760
For example, the first line
describes these three cells;

1424
01:25:33,760 --> 01:25:35,960
the given formula is placed
in the top-left cell

1425
01:25:35,960 --> 01:25:37,080
and copied to the others

1426
01:25:37,080 --> 01:25:39,080
with the usual adjustment
of relative references.

1427
01:25:40,480 --> 01:25:42,360
We can now write the elastic SDF

1428
01:25:42,360 --> 01:25:43,720
that we want in this notation

1429
01:25:43,720 --> 01:25:45,600
by introducing a length
variable α

1430
01:25:45,600 --> 01:25:47,640
that can take any nonnegative
integer value.

1431
01:25:48,200 --> 01:25:51,680
Of course, if we set α to 3,
we get the original SHOP back.

1432
01:25:51,680 --> 01:25:54,680
We'll call this elastic SDF SHOP1
for reference in this talk,

1433
01:25:54,680 --> 01:25:57,320
though the user would invoke it
using the original name SHOP.

1434
01:25:58,720 --> 01:26:00,800
When an elastic SDF is called,

1435
01:26:00,800 --> 01:26:03,760
we set the length variables
to match the argument sizes,

1436
01:26:03,760 --> 01:26:05,800
in this case setting α to 6,

1437
01:26:05,800 --> 01:26:07,560
and substitute them
into the definition,

1438
01:26:07,560 --> 01:26:10,440
giving an ordinary SDF that
we can evaluate as before.

1439
01:26:11,080 --> 01:26:13,680
Note that tiles may
collide when they expand.

1440
01:26:13,680 --> 01:26:15,680
We address this by
labeling each reference

1441
01:26:15,680 --> 01:26:17,840
with the tile or tiles it
originally pointed to

1442
01:26:17,840 --> 01:26:19,680
and having it read only
from those tiles,

1443
01:26:19,680 --> 01:26:21,760
even if others overlap them.

1444
01:26:21,760 --> 01:26:24,880
Here, the reference in the SUM
reads the H7 of tile 4,

1445
01:26:24,880 --> 01:26:28,160
while the output reference reads
the H7 of tile 5.

1446
01:26:28,160 --> 01:26:29,480
We do this for all SDFs, but

1447
01:26:29,480 --> 01:26:30,960
to reduce clutter, we won't show

1448
01:26:30,960 --> 01:26:32,520
the labels for the rest of the talk.

1449
01:26:34,280 --> 01:26:35,880
The question immediately comes up:

1450
01:26:35,880 --> 01:26:38,880
is the best generalization of
a given SDF always clear?

1451
01:26:38,880 --> 01:26:41,760
For one thing, we want
a generalization that's well defined,

1452
01:26:41,760 --> 01:26:43,520
meaning that its
references stay in bounds

1453
01:26:43,520 --> 01:26:45,680
for all values of length variables.

1454
01:26:45,680 --> 01:26:47,440
For example, if we set the height

1455
01:26:47,440 --> 01:26:49,120
of the column-H tile to α

1456
01:26:49,120 --> 01:26:51,040
but the height of
the column-G tile to 3,

1457
01:26:51,040 --> 01:26:53,520
then when α increases, the H tile

1458
01:26:53,520 --> 01:26:56,160
will be referring to undefined
cells below the G tile,

1459
01:26:56,160 --> 01:26:58,520
so this generalization
is not well defined.

1460
01:26:58,520 --> 01:27:01,520
From now on, we'll consider only
well defined generalizations.

1461
01:27:02,800 --> 01:27:04,040
To illustrate the next point,

1462
01:27:04,040 --> 01:27:06,240
consider this contrived SUM2 SDF

1463
01:27:06,240 --> 01:27:08,600
that sums two arrays
and adds the totals.

1464
01:27:08,600 --> 01:27:10,840
Here are two well
defined generalizations:

1465
01:27:10,840 --> 01:27:13,880
SUM2_D allows the arrays to be
different lengths α and β,

1466
01:27:13,880 --> 01:27:17,160
while SUM2_S requires them
to be the same length α.

1467
01:27:17,160 --> 01:27:20,040
We say that SUM2_D is more
general than SUM2_S

1468
01:27:20,040 --> 01:27:21,880
since it can be
converted to SUM2_S

1469
01:27:21,880 --> 01:27:24,080
by substituting for
the length variables.

1470
01:27:24,080 --> 01:27:26,080
We prefer SUM2_D to make sure

1471
01:27:26,080 --> 01:27:27,840
we generalize as many
degrees of freedom

1472
01:27:27,840 --> 01:27:29,840
in the original SDF as possible.

1473
01:27:31,080 --> 01:27:33,120
So given an SDF like SHOP,

1474
01:27:33,120 --> 01:27:34,640
if there's a well
defined generalization

1475
01:27:34,640 --> 01:27:36,480
that is more general
than all the others,

1476
01:27:36,480 --> 01:27:37,680
which we call principal,

1477
01:27:37,680 --> 01:27:38,960
that's the one we want.

1478
01:27:38,960 --> 01:27:40,680
Unfortunately, there
are several problems

1479
01:27:40,680 --> 01:27:42,920
that can cause there to be no
principal generalization;

1480
01:27:42,920 --> 01:27:44,680
we'll look at one of them.

1481
01:27:44,680 --> 01:27:46,000
In addition to SHOP1

1482
01:27:46,000 --> 01:27:48,720
that we saw earlier, SHOP
has two other contrived,

1483
01:27:48,720 --> 01:27:50,520
but well defined, generalizations:

1484
01:27:50,520 --> 01:27:52,280
one that uses only
the first three items

1485
01:27:52,280 --> 01:27:54,960
of the input and one
that uses only the last three.

1486
01:27:54,960 --> 01:27:57,080
None of these generalizations
can be converted

1487
01:27:57,080 --> 01:27:59,520
to any of the others by
substituting for α.

1488
01:27:59,520 --> 01:28:00,600
And since they can all give

1489
01:28:00,600 --> 01:28:02,240
different answers on the same input,

1490
01:28:02,240 --> 01:28:03,560
it should be intuitively clear

1491
01:28:03,560 --> 01:28:05,240
there isn't a principal
generalization

1492
01:28:05,240 --> 01:28:07,120
that's more general than all three.

1493
01:28:07,120 --> 01:28:08,600
The user probably wants SHOP1,

1494
01:28:08,600 --> 01:28:10,760
but we have to
formalize that somehow.

1495
01:28:10,760 --> 01:28:13,560
So we introduce a concept
of a regular generalization,

1496
01:28:13,560 --> 01:28:16,800
which satisfies several conditions
on top of well-definedness,

1497
01:28:16,800 --> 01:28:18,200
one of which is that
a cell reference

1498
01:28:18,200 --> 01:28:20,560
can't pick three elements
out of a larger tile.

1499
01:28:20,560 --> 01:28:21,680
So SHOP1 is regular

1500
01:28:21,680 --> 01:28:23,680
and the other two
generalizations are not.

1501
01:28:25,320 --> 01:28:27,400
Now, out of all the well
defined generalizations

1502
01:28:27,400 --> 01:28:30,960
of an SDF, if we keep only
the regular generalizations,

1503
01:28:30,960 --> 01:28:32,160
we can prove that there's

1504
01:28:32,160 --> 01:28:34,480
always a principal
regular generalization.

1505
01:28:34,480 --> 01:28:37,360
And that's the elastic SDF we use.

1506
01:28:37,360 --> 01:28:38,920
This can be seen as the analogue

1507
01:28:38,920 --> 01:28:42,240
of the principal type of a term in a
functional programming language.

1508
01:28:44,120 --> 01:28:45,640
Our algorithm to find the principal

1509
01:28:45,640 --> 01:28:48,160
regular generalization
introduces all the variables

1510
01:28:48,160 --> 01:28:49,920
it could possibly need,

1511
01:28:49,920 --> 01:28:51,520
generates constraints on them

1512
01:28:51,520 --> 01:28:53,440
based on the definition
of regularity,

1513
01:28:53,960 --> 01:28:55,920
and then solves the constraints.

1514
01:28:55,920 --> 01:28:57,960
For example, because of
the relative reference

1515
01:28:57,960 --> 01:29:00,440
between the tiles in
columns G and H,

1516
01:29:00,440 --> 01:29:01,960
we generate a constraint that

1517
01:29:01,960 --> 01:29:03,720
the heights of those tiles are equal.

1518
01:29:03,720 --> 01:29:06,160
Again, this is analogous to
a type inference algorithm

1519
01:29:06,160 --> 01:29:07,880
in a functional
programming language.

1520
01:29:10,240 --> 01:29:12,840
We've seen that in order to have
a principal generalization,

1521
01:29:12,840 --> 01:29:15,040
we needed to introduce
a concept of regularity

1522
01:29:15,040 --> 01:29:17,720
that excludes some well
defined generalizations.

1523
01:29:17,720 --> 01:29:19,520
We try to make
it capture user intent,

1524
01:29:19,520 --> 01:29:22,600
which inevitably involves
judgment calls. Our goals,

1525
01:29:22,600 --> 01:29:25,120
aside from having a principal
regular generalization,

1526
01:29:25,120 --> 01:29:29,000
are to support as many realistic
SDF design patterns as we can

1527
01:29:29,000 --> 01:29:31,160
and keep the process
predictable for users,

1528
01:29:31,160 --> 01:29:33,480
even if they don't know
the detailed rules.

1529
01:29:33,480 --> 01:29:35,000
Our work represents a first draft

1530
01:29:35,000 --> 01:29:38,000
of the definition;
we expect that future work will refine it.

1531
01:29:39,480 --> 01:29:40,920
This is all technically elegant,

1532
01:29:40,920 --> 01:29:42,680
but we need to make
sure we're actually

1533
01:29:42,680 --> 01:29:44,800
making things easier for users.

1534
01:29:44,800 --> 01:29:47,400
So we did a user study
to compare elastic SDFs

1535
01:29:47,400 --> 01:29:48,840
to the best existing alternative,

1536
01:29:48,840 --> 01:29:51,440
namely array programming,
on a set of tasks

1537
01:29:51,440 --> 01:29:54,280
based on real world spreadsheets
we previously collected.

1538
01:29:55,760 --> 01:29:58,040
I'd like to highlight
a few findings.

1539
01:29:58,040 --> 01:29:59,880
First, users experienced
lower cognitive

1540
01:29:59,880 --> 01:30:03,360
workload using elastic SDFs
compared to array programming,

1541
01:30:03,360 --> 01:30:04,680
based on a standard survey

1542
01:30:04,680 --> 01:30:07,000
called the NASA Task Load Index.

1543
01:30:07,000 --> 01:30:08,840
Second, we have partial
data suggesting

1544
01:30:08,840 --> 01:30:10,920
that users solved tasks
faster on average

1545
01:30:10,920 --> 01:30:13,400
using elastic SDFs compared
to array programming.

1546
01:30:14,080 --> 01:30:16,000
And finally, while users
stated a preference

1547
01:30:16,000 --> 01:30:17,920
for array programming
for simple tasks,

1548
01:30:17,920 --> 01:30:21,000
they preferred elastic SDFs
for more complex tasks.

1549
01:30:21,000 --> 01:30:23,200
This is no surprise
given that complex tasks

1550
01:30:23,200 --> 01:30:25,640
are much harder to solve
with array programming.

1551
01:30:25,640 --> 01:30:27,520
These results are
really promising, though

1552
01:30:27,520 --> 01:30:30,480
more work is needed to further
optimize the user experience.

1553
01:30:32,240 --> 01:30:34,680
So, we've seen briefly
how we can use ideas

1554
01:30:34,680 --> 01:30:36,960
from programming language
theory to offer spreadsheet

1555
01:30:36,960 --> 01:30:40,800
users an easier way to reuse logic
on inputs of different sizes.

1556
01:30:40,800 --> 01:30:43,840
You can find the full definitions,
algorithms, and proofs in the paper.

1557
01:30:44,480 --> 01:30:46,160
We look forward to making
this functionality

1558
01:30:46,160 --> 01:30:48,640
widely available to improve
user productivity.

1559
01:30:48,640 --> 01:30:49,800
Thanks for listening,

1560
01:30:49,800 --> 01:30:52,160
and we look forward to your
questions and feedback.

1561
01:30:52,760 --> 01:30:58,640
(CLAPPING BACKGROUND)

1562
01:31:00,120 --> 01:31:04,200
JEREMY: Thanks Matt, if you're watching
the New York streaming Clowdr.

1563
01:31:04,200 --> 01:31:06,120
You should now see a Q&A link,

1564
01:31:06,120 --> 01:31:08,000
where you can ask Matt
questions by video chat.

1565
01:31:13,720 --> 01:31:16,160
The next and final
talk in this session

1566
01:31:16,160 --> 01:31:17,400
is a presentation of
the paper,

1567
01:31:17,400 --> 01:31:21,480
Emerging Languages and Alternative
Approach to Teaching Programming Languages

1568
01:31:21,480 --> 01:31:24,960
by Saverio Perugini, which argues that a
course on

1569
01:31:24,960 --> 01:31:27,680
the principles of programming
languages should not be structured

1570
01:31:27,680 --> 01:31:30,680
according to those principles,
but around emerging languages

1571
01:31:30,680 --> 01:31:33,240
such as Lula and Elixir instead.

1572
01:31:34,760 --> 01:31:37,600
SAVERIO PERUGINI: Hello, my name
is Saverio Perugini.

1573
01:31:38,480 --> 01:31:40,880
And today I'm going to be presenting

1574
01:31:40,880 --> 01:31:44,240
our journal of functional programming
paper emerging languages

1575
01:31:44,240 --> 01:31:47,600
an alternative approach to
teaching programming languages.

1576
01:31:47,600 --> 01:31:52,120
I'm in the Department of Computer
Science at the University of Dayton.

1577
01:31:55,600 --> 01:31:57,400
So, while the learning outcomes

1578
01:31:57,400 --> 01:32:00,720
of a course in programming
languages are well established

1579
01:32:00,720 --> 01:32:02,480
the most effective approach

1580
01:32:02,480 --> 01:32:06,360
to teach a languages course,
is not a settled matter.

1581
01:32:06,360 --> 01:32:08,880
There is, there are
a myriad of approaches

1582
01:32:08,880 --> 01:32:10,680
there the two predominant approaches

1583
01:32:10,680 --> 01:32:12,840
are the principles slash
concepts based approach

1584
01:32:12,840 --> 01:32:14,800
and the interpreter based approach.

1585
01:32:14,800 --> 01:32:17,880
There's also a paradigm
survey based approach,

1586
01:32:17,880 --> 01:32:19,920
there are hybrids of these.

1587
01:32:19,920 --> 01:32:21,200
Each involve challenges

1588
01:32:22,360 --> 01:32:27,320
In this work we challenge the idea
that a course intended

1589
01:32:27,320 --> 01:32:29,960
to convey the concepts of languages

1590
01:32:29,960 --> 01:32:36,000
should therefore be structured,
according to those concepts.

1591
01:32:36,000 --> 01:32:38,800
We saught to teach programming languages
from a different perspective,

1592
01:32:39,440 --> 01:32:42,680
the approach we developed involves

1593
01:32:42,680 --> 01:32:45,960
using emerging languages
as a conduit through

1594
01:32:45,960 --> 01:32:50,240
which students incidentally bump
into the concepts of languages,

1595
01:32:50,240 --> 01:32:52,600
the implementation options
available for them,

1596
01:32:52,600 --> 01:32:56,240
and the compelling consequences
of those options on programming,

1597
01:32:56,240 --> 01:32:59,680
which are the student learning
outcomes the SLOs,

1598
01:32:59,680 --> 01:33:01,360
of a course in programming languages.

1599
01:33:01,840 --> 01:33:05,520
Now, when we say emerging languages

1600
01:33:05,520 --> 01:33:08,360
what we mean here is languages

1601
01:33:08,360 --> 01:33:11,960
that have adopted functional
features to some extent or another.

1602
01:33:11,960 --> 01:33:13,800
In the last 20 years or so

1603
01:33:13,800 --> 01:33:18,000
so languages like lula
elixir, go, python, and so on.

1604
01:33:18,800 --> 01:33:21,600
And despite the moniker
for this approach.

1605
01:33:21,600 --> 01:33:23,520
The goal here is not
to teach students,

1606
01:33:23,520 --> 01:33:27,800
emerging languages, and thus
the course must not evolve,

1607
01:33:28,480 --> 01:33:32,360
or perhaps I should say
devolve, into an isolated rote

1608
01:33:32,360 --> 01:33:35,480
investigation of a sequence
of emerging languages.

1609
01:33:35,480 --> 01:33:37,520
Rather, the goal here
is to teach students

1610
01:33:37,520 --> 01:33:40,320
the principles concepts
of languages.

1611
01:33:40,320 --> 01:33:44,440
As an intended, though
unadvertised, side effect

1612
01:33:44,440 --> 01:33:46,240
of covering these
emerging languages,

1613
01:33:46,240 --> 01:33:51,640
under the guise of a survey course
on a variety of hot new languages.

1614
01:33:53,480 --> 01:33:56,920
The central thesis of this work is
that this alternative approach,

1615
01:33:57,840 --> 01:34:02,760
results in a variety of
course deezer durata,

1616
01:34:03,560 --> 01:34:07,600
scope for an instructor
customization, alignment

1617
01:34:07,600 --> 01:34:11,040
with current trends in language
evolution, practice and research,

1618
01:34:11,600 --> 01:34:16,200
and probably better aligned
with industrial needs.

1619
01:34:18,520 --> 01:34:21,800
What I'm going to discuss
here is the rationale for.

1620
01:34:23,080 --> 01:34:27,640
the course mechanics supporting,
and the consequences of this approach.

1621
01:34:29,640 --> 01:34:32,960
So, the rationale for
the emerging languages approach

1622
01:34:32,960 --> 01:34:35,560
is based on some simple ideas.

1623
01:34:35,560 --> 01:34:38,920
First, let's recognize that

1624
01:34:38,920 --> 01:34:43,040
students think in terms of
languages, not concepts.

1625
01:34:43,040 --> 01:34:46,800
I call that the the students
language-centric perspective,

1626
01:34:46,800 --> 01:34:49,200
learning concepts of
programming language itself

1627
01:34:49,200 --> 01:34:51,120
sounds dull and academic
learning languages,

1628
01:34:51,120 --> 01:34:53,160
especially new and emerging ones,

1629
01:34:53,160 --> 01:34:55,080
and how those languages
apply in domains

1630
01:34:55,080 --> 01:34:57,480
in which students have passion.

1631
01:34:57,480 --> 01:35:00,160
Like game programming,
Internet of Things,

1632
01:35:00,160 --> 01:35:02,440
web frameworks, sounds like fun.

1633
01:35:02,440 --> 01:35:06,600
So why not take advantage of
the juxtaposition of the circumstances.

1634
01:35:06,600 --> 01:35:09,880
If we tell students we're going to,
they're going to to learn the lula.

1635
01:35:09,880 --> 01:35:13,400
Python, Ruby, that's something
they can get excited about.

1636
01:35:13,880 --> 01:35:16,600
Let's get students excited
about what they're studying

1637
01:35:16,600 --> 01:35:21,760
and then most effectively
harness that motivating

1638
01:35:21,760 --> 01:35:25,240
spirit to meet the learning
outcomes of the course.

1639
01:35:26,040 --> 01:35:28,560
Exploring the concepts,
implementation options,

1640
01:35:28,560 --> 01:35:31,200
and then the implications of
those options on programming.

1641
01:35:32,680 --> 01:35:37,680
So, step one, students and concepts:
think languages, not concepts.

1642
01:35:38,320 --> 01:35:40,600
Let's further recognize,
that students are motivated

1643
01:35:40,600 --> 01:35:41,960
to learn emerging technologies

1644
01:35:41,960 --> 01:35:45,440
they perceive as relevant
to the software industry,

1645
01:35:45,440 --> 01:35:47,640
even if the only
ephemerally relevant.

1646
01:35:48,320 --> 01:35:52,840
That's what I would call the student
relevance centric perspective.

1647
01:35:52,840 --> 01:35:56,880
Most average students are
typically not going to get excited

1648
01:35:56,880 --> 01:35:59,920
about a required concepts of
programming languages course,

1649
01:36:00,440 --> 01:36:02,600
whose description indicates the use

1650
01:36:02,600 --> 01:36:05,680
of Lisp as
an implementation language,

1651
01:36:05,680 --> 01:36:09,360
which the students perceive as
not being used in industry,

1652
01:36:09,360 --> 01:36:13,160
not building the resume
and not helping them get a job.

1653
01:36:14,040 --> 01:36:16,920
Students, however, are motivated
to learn new hot languages

1654
01:36:16,920 --> 01:36:19,240
and novel emerging technologies.

1655
01:36:19,240 --> 01:36:21,400
Students perceive emerging languages

1656
01:36:21,400 --> 01:36:23,560
like Python and Ruby
as less academic,

1657
01:36:24,120 --> 01:36:27,480
more fun and more practically
applicable to real world problems

1658
01:36:28,640 --> 01:36:31,960
than languages like Lisp, which they
perceive as archaic and arcane.

1659
01:36:32,480 --> 01:36:35,760
I think the reason
for this perception

1660
01:36:35,760 --> 01:36:37,400
is that this perception is formed

1661
01:36:37,400 --> 01:36:41,360
and influenced by the culture
of the online ecosystem

1662
01:36:41,360 --> 01:36:44,400
in which students explore
probe experiences,

1663
01:36:44,400 --> 01:36:46,720
new languages and new
technologies on their own.

1664
01:36:47,240 --> 01:36:51,680
Things like vlogs, YouTube videos,
StackOverflow, GitHub, and so on.

1665
01:36:53,480 --> 01:36:56,040
So why can't we teach
students first class

1666
01:36:56,040 --> 01:36:59,760
in high order functions and closures
in Python rather than Lisp?

1667
01:36:59,760 --> 01:37:01,680
I mean, ultimately, nobody cares

1668
01:37:01,680 --> 01:37:03,040
if a student can program less

1669
01:37:03,040 --> 01:37:05,440
rather, they care
if a student can think

1670
01:37:05,440 --> 01:37:08,440
like a Lisp programmer in
higher order abstractions.

1671
01:37:08,440 --> 01:37:11,080
metaprogramming and
a variety of other languages.

1672
01:37:12,600 --> 01:37:16,960
So let's harness that process
of programming language

1673
01:37:16,960 --> 01:37:18,560
acculturation incubation in which

1674
01:37:18,560 --> 01:37:21,400
students participate,
perhaps unconsciously.

1675
01:37:23,120 --> 01:37:26,760
Given those circumstances,
we think it's reasonable

1676
01:37:26,760 --> 01:37:28,880
to use emerging
languages as a method

1677
01:37:28,880 --> 01:37:31,240
or conduit by which to distill

1678
01:37:31,240 --> 01:37:34,320
distill concepts of
languages to students.

1679
01:37:35,480 --> 01:37:39,520
And then of course, let's build
a course framework around that idea.

1680
01:37:39,520 --> 01:37:41,720
And let's use course
mechanics that leverage

1681
01:37:41,720 --> 01:37:45,400
how students learn languages on
their own, to teach them concepts.

1682
01:37:47,720 --> 01:37:50,040
So that's what we did. We
designed a course framework

1683
01:37:50,040 --> 01:37:52,120
to support that approach
or to

1684
01:37:52,120 --> 01:37:54,000
operationalize that approach.

1685
01:37:54,000 --> 01:37:58,440
And the model we came
up with involves three

1686
01:37:58,440 --> 01:38:01,160
it's a module based approach.
It involves three modules.

1687
01:38:01,160 --> 01:38:03,160
It's a modular based
design, I should say,

1688
01:38:03,160 --> 01:38:04,600
involves three modules.

1689
01:38:05,120 --> 01:38:06,640
Students were given a foundation

1690
01:38:06,640 --> 01:38:09,000
and a vocabulary in language,

1691
01:38:09,000 --> 01:38:11,640
a brief foundation of vocabulary
in language concepts

1692
01:38:11,640 --> 01:38:14,000
through sort of a functional
programming tutorial

1693
01:38:14,000 --> 01:38:17,880
in module one which which was formed

1694
01:38:17,880 --> 01:38:20,040
the background from
which they deconstructed

1695
01:38:20,040 --> 01:38:23,520
the emerging languages
presented in module two

1696
01:38:23,520 --> 01:38:25,800
deconstruct those languages
into the concepts

1697
01:38:25,800 --> 01:38:29,080
and then probe those
concepts for subsequent

1698
01:38:30,240 --> 01:38:32,480
comparisons synthesis
use application

1699
01:38:33,000 --> 01:38:39,120
of those concepts in final
culminating projects in module three,

1700
01:38:39,120 --> 01:38:44,120
so, Module one, Brief Introduction
Identification of Language Concepts,

1701
01:38:44,120 --> 01:38:47,040
Module two Deconstructing the Emerging

1702
01:38:47,040 --> 01:38:50,000
Languages Presented to Prove those
Concepts

1703
01:38:50,000 --> 01:38:53,520
and Module three Reconstruct,
Reconstruct, Synthesise,

1704
01:38:53,520 --> 01:38:56,760
apply those Concepts in,
in, in Projects.

1705
01:38:56,760 --> 01:39:00,520
now, that that third
module also helps

1706
01:39:00,520 --> 01:39:04,600
connect those languages back to
the concepts in module one.

1707
01:39:05,160 --> 01:39:12,360
Module two is really the
the heart and soul of the course

1708
01:39:12,360 --> 01:39:17,400
that the most number of
weeks, six to eight weeks,

1709
01:39:17,400 --> 01:39:20,280
it's really the the body of
the course the meat of the course.

1710
01:39:21,880 --> 01:39:24,160
Now, I do want to
mention in module two

1711
01:39:24,160 --> 01:39:26,160
module two is really
where the instructor

1712
01:39:26,160 --> 01:39:30,400
has the opportunity to
emulate as much as possible

1713
01:39:30,400 --> 01:39:33,640
the process by which students
learn languages on their own

1714
01:39:33,640 --> 01:39:37,040
through those those online
fora I was discussing earlier.

1715
01:39:37,040 --> 01:39:39,240
So this is the module where we,

1716
01:39:40,880 --> 01:39:44,920
we, we did YouTube videos, we did.

1717
01:39:47,120 --> 01:39:50,280
Language cheat sheets or
quick reference sheets.

1718
01:39:50,280 --> 01:39:55,600
We did online style, blog webpages,
we did language Synopses.

1719
01:39:56,320 --> 01:39:58,040
A lot of active learning going on.

1720
01:39:58,040 --> 01:40:01,160
Students presented each language

1721
01:40:01,160 --> 01:40:04,040
over the course of two
consecutive 75 minute periods

1722
01:40:04,040 --> 01:40:05,720
really trying to emulate the process

1723
01:40:05,720 --> 01:40:08,440
by white, by which students
learn, learn languages.

1724
01:40:10,080 --> 01:40:15,120
This also provide a graded
preparation for their final,

1725
01:40:15,120 --> 01:40:16,120
the same sort of mechanics that

1726
01:40:16,120 --> 01:40:17,720
we're using their final
culminating project.

1727
01:40:19,200 --> 01:40:21,600
We've offered this
course three times

1728
01:40:21,600 --> 01:40:23,560
three offerings using this approach.

1729
01:40:23,560 --> 01:40:25,040
And these are some of the languages

1730
01:40:25,040 --> 01:40:27,560
that we use, across some
of those offerings.

1731
01:40:27,560 --> 01:40:28,960
This is a subset of them.

1732
01:40:29,880 --> 01:40:33,320
And this is are
the student artifacts

1733
01:40:33,320 --> 01:40:35,040
and final projects and cheat sheets

1734
01:40:35,040 --> 01:40:37,960
and YouTube videos are all
posted in this GitHub site,

1735
01:40:37,960 --> 01:40:39,520
which I probably won't be able

1736
01:40:39,520 --> 01:40:42,520
to demonstrate or at
least illustrate later.

1737
01:40:46,400 --> 01:40:48,680
Module three is really the module

1738
01:40:48,680 --> 01:40:51,320
where where students are
given the opportunity

1739
01:40:51,320 --> 01:40:54,040
to demonstrate a mastery of
those concepts distilled

1740
01:40:54,040 --> 01:40:57,120
during the emerging
languages presentations.

1741
01:40:58,040 --> 01:41:00,080
and really demonstrate
how they can use

1742
01:41:00,080 --> 01:41:02,920
their intuition to
independently discern

1743
01:41:02,920 --> 01:41:05,920
how and when and creatively harness

1744
01:41:06,400 --> 01:41:08,160
an integration of a subset
of those concept

1745
01:41:08,800 --> 01:41:11,920
that they absorbed
in that module to craft a

1746
01:41:11,920 --> 01:41:16,600
solution to a practical computing
problem in module three.

1747
01:41:16,600 --> 01:41:21,080
The project involved the software
system, a formal term paper

1748
01:41:21,080 --> 01:41:24,560
using the ACM conference
style and LaTeX and

1749
01:41:24,560 --> 01:41:26,840
an in class presentation
to classmates.

1750
01:41:26,840 --> 01:41:33,560
Now without a formal research
experiment, it's challenging to

1751
01:41:33,560 --> 01:41:35,480
ascertain the merit
of this approach and

1752
01:41:35,480 --> 01:41:36,920
helping students understand,

1753
01:41:36,920 --> 01:41:38,800
understand the core
language concepts.

1754
01:41:38,800 --> 01:41:42,440
We can, however, offer some
anecdotal and formal evidence.

1755
01:41:42,440 --> 01:41:46,280
This table I'm showing you here
presents the observed frequency

1756
01:41:46,280 --> 01:41:49,960
of the use of language concepts
of the language concepts

1757
01:41:49,960 --> 01:41:51,880
in the source code of
the final projects.

1758
01:41:51,880 --> 01:41:57,040
Now, again, while the observation
of an application and

1759
01:41:57,040 --> 01:41:59,920
integration and a use of these
concepts in the final and

1760
01:41:59,920 --> 01:42:03,960
the final projects cannot on its
own serve as formal evidence

1761
01:42:03,960 --> 01:42:05,680
that they understood the concepts.

1762
01:42:05,680 --> 01:42:08,400
It does provide some
anecdotal evidence,

1763
01:42:08,400 --> 01:42:11,520
particularly because many
of these projects were

1764
01:42:11,520 --> 01:42:14,880
of high quality and some
were even published.

1765
01:42:15,600 --> 01:42:19,560
OK. wrapping up here,
what are the what can you

1766
01:42:19,560 --> 01:42:21,920
expect from this approach?
What are the consequences.

1767
01:42:21,920 --> 01:42:26,720
It's customizable. The
instructors picking

1768
01:42:26,720 --> 01:42:28,040
different languages every semester.

1769
01:42:28,040 --> 01:42:29,800
The mechanics are
somewhat customizable,

1770
01:42:29,800 --> 01:42:33,080
although to a lesser extent, because
we're trying to use mechanics,

1771
01:42:33,080 --> 01:42:36,080
which, which one of the main
ideas here is using mechanics,

1772
01:42:36,080 --> 01:42:38,320
which would dovetail
nicely with how students

1773
01:42:38,320 --> 01:42:39,800
learn languages on their own.

1774
01:42:39,800 --> 01:42:42,520
It gets students away from
their Java-centric worldview.

1775
01:42:42,520 --> 01:42:44,160
We're covering a wide
spectrum of languages

1776
01:42:44,160 --> 01:42:45,800
in a relatively short
period of time,

1777
01:42:45,800 --> 01:42:51,160
which really radically shatters
students' Java-centric worldview,

1778
01:42:51,160 --> 01:42:54,760
promoting the idea that
students should use languages

1779
01:42:55,320 --> 01:42:58,880
for the particular problem
domain we're covering things

1780
01:42:58,880 --> 01:43:02,760
like you know, a new
concurrency models.

1781
01:43:02,760 --> 01:43:07,440
CSP, actor, Julia, scientific
computing, game

1782
01:43:07,440 --> 01:43:12,320
programming, MapReduce and so on.
Promotes academic integrity.

1783
01:43:12,320 --> 01:43:15,920
You're rotating the languages
out every semester.

1784
01:43:15,920 --> 01:43:19,920
Doesn't require a big inordinate,
and excess of work on the

1785
01:43:19,920 --> 01:43:23,480
instructors part because the students
are producing the artifacts.

1786
01:43:23,480 --> 01:43:25,320
It doesn't compromise
learning outcomes.

1787
01:43:25,320 --> 01:43:28,680
The outcomes are the same,
the mechanisms different.

1788
01:43:28,680 --> 01:43:32,680
Aligns well with industrial
needs, promotes professional

1789
01:43:33,560 --> 01:43:35,080
preparation
and academic preparation.

1790
01:43:35,080 --> 01:43:38,120
Of course, there are challenges.
Scaling the approach

1791
01:43:38,120 --> 01:43:41,080
is certainly a challenge,
especially in sections with large

1792
01:43:41,080 --> 01:43:44,400
number of students, 50
to a hundred students.

1793
01:43:44,400 --> 01:43:48,080
There's an entire section of
the paper dedicated to some

1794
01:43:48,080 --> 01:43:52,880
sort of rough calculations
on how you might adapt

1795
01:43:52,880 --> 01:43:54,280
the approach to large sections.

1796
01:43:54,280 --> 01:43:55,920
There are some other
challenges as well,

1797
01:43:55,920 --> 01:43:57,440
which are mentioned in the paper.

1798
01:43:57,440 --> 01:44:01,920
Concluding the idea presented
here, the approach presented

1799
01:44:01,920 --> 01:44:04,280
here is based on the idea that
we should teach programming

1800
01:44:04,280 --> 01:44:06,960
languages to students in
a mode that meshes well and

1801
01:44:06,960 --> 01:44:11,480
leverages both how students
think languages, not concepts.

1802
01:44:11,480 --> 01:44:16,880
They put languages before
concepts and how they learn

1803
01:44:16,880 --> 01:44:19,760
languages and new technologies
on their own online for

1804
01:44:19,760 --> 01:44:21,920
YouTube videos, stack overflow
and things like that.

1805
01:44:21,920 --> 01:44:26,480
I hope my goal with this
presentation in this paper is that

1806
01:44:26,480 --> 01:44:28,600
get the discussion going,
challenge the idea,

1807
01:44:28,600 --> 01:44:29,920
how we teach programming languages.

1808
01:44:29,920 --> 01:44:32,600
I hope it encouraged people to
think this folks that think

1809
01:44:32,600 --> 01:44:36,640
differently and to bring this
back to their institutions.

1810
01:44:37,720 --> 01:44:44,680
I encourage you to explore our
webpages, especially our GitHub site,

1811
01:44:44,680 --> 01:44:50,320
which involves all the the language
Synopses, YouTube videos,

1812
01:44:50,320 --> 01:44:52,880
presentations, and then some of
the projects are posted as well.

1813
01:44:52,880 --> 01:44:55,000
At this point, I'd like to
thank you for your attention.

1814
01:44:55,000 --> 01:44:57,160
And I certainly welcome
you to contact me

1815
01:44:57,160 --> 01:45:00,400
with questions
and comments. Thank you.

1816
01:45:02,240 --> 01:45:09,280
(CLAPS)

1817
01:45:09,280 --> 01:45:13,280
JEREMY: Thanks. I'm afraid that
Saverio is not available for

1818
01:45:13,280 --> 01:45:15,840
live Q&A So that
ends this session.

1819
01:45:15,840 --> 01:45:20,840
Please do, let me know what
you think of this scheme. Bye.

1820
01:46:06,200 --> 01:50:09,120
(UPLIFTING ORCHESTRAL MUSIC)

1821
01:50:59,200 --> 01:53:49,400
(UPLIFTING ORCHESTRAL MUSIC)

1822
01:54:57,840 --> 01:57:25,440
(UPLIFTING ORCHESTRAL MUSIC)

